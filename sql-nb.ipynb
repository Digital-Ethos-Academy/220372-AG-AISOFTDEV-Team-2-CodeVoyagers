{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "We load the `day1_prd.md` artifact from Day 1. This document is the single source of truth for our project's requirements and provides the essential context for the LLM to generate a relevant and accurate database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\n",
      "Project root directory: c:\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:44:23,365 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "2025-11-05 14:44:24,536 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, recommended_models_table, prompt_enhancer\n",
    "\n",
    "# Initialize separate LLM clients for different artifacts to use the latest models from different providers.\n",
    "# - Schema generation uses a strong instruction-following model\n",
    "# - Seed data generation uses a model tuned for data generation\n",
    "schema_client, schema_model_name, schema_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "seed_client, seed_model_name, seed_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD\n",
    "prd_content = load_artifact(\"artifacts/project_prd.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load prd_content = artifacts/project_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 - Generating the SQL Schema (SQLite)\n",
    "\n",
    "**Explanation:**\n",
    "This prompt instructs the LLM to act as a Database Administrator (DBA) and generate a SQL schema specifically compatible with SQLite.\n",
    "\n",
    "Guidance for the LLM and the developer:\n",
    "- Output only `CREATE TABLE` statements and associated `CREATE INDEX` statements where helpful. Do not include any surrounding markdown fences or explanatory text in the SQL output.\n",
    "- Use SQLite-compatible types and conventions: prefer `INTEGER`, `TEXT`, `REAL`, `BLOB`, and `NUMERIC`. For auto-incrementing primary keys use `INTEGER PRIMARY KEY AUTOINCREMENT`. Do NOT use `SERIAL`, `BIGSERIAL`, `AUTO_INCREMENT`, or PostgreSQL/MySQL-specific types or DDL.\n",
    "- Avoid features not supported by SQLite such as `ALTER TABLE ... DROP COLUMN`, `CHECK` constraints that reference subqueries, or advanced index types. Keep DDL portable for SQLite's capabilities.\n",
    "- Use `FOREIGN KEY` clauses only where appropriate; remember that SQLite enforces foreign keys only when `PRAGMA foreign_keys = ON` is set by the application.\n",
    "- Provide sensible column constraints (`NOT NULL`, `UNIQUE`) and default values using SQLite-supported expressions.\n",
    "\n",
    "We will post-process the LLM response with `clean_llm_output(..., language='sql')` to strip markdown and save the pure SQL to `artifacts/schema.sql`. The notebook later uses `cursor.executescript()` to run the SQL, so ensure the output is a single SQL script containing multiple statements separated by semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 14:54:04,769 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "ename": "ProviderOperationError",
     "evalue": "[openai:o3] prompt enhancement error: [openai:o3] completion error: Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py:156\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mstart_tls\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     stream = \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py:154\u001b[39m, in \u001b[36mSyncStream.start_tls\u001b[39m\u001b[34m(self, ssl_context, server_hostname, timeout)\u001b[39m\n\u001b[32m    150\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    151\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    152\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    153\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    155\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\openai\\_base_client.py:982\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1032)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\providers\\openai.py:125\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].text\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m api_error\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover - network dependent\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\providers\\openai.py:106\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    105\u001b[39m     chat_params[\u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m] = temperature\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m response = \u001b[43m_call_with_temperature_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchat_params\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\providers\\openai.py:70\u001b[39m, in \u001b[36m_call_with_temperature_retry\u001b[39m\u001b[34m(operation, params)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1146\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1256\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1014\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1013\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising connection error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1016\u001b[39m log.debug(\n\u001b[32m   1017\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1018\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     response.headers,\n\u001b[32m   1023\u001b[39m )\n",
      "\u001b[31mAPIConnectionError\u001b[39m: Connection error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProviderOperationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\llm.py:509\u001b[39m, in \u001b[36mprompt_enhancer\u001b[39m\u001b[34m(user_input, model_name, client, api_provider)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderOperationError(\n\u001b[32m    500\u001b[39m         provider \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    501\u001b[39m         model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    507\u001b[39m         ),\n\u001b[32m    508\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m enhanced_prompt = \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimization_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m    \u001b[49m\u001b[43mactual_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m enhanced_prompt.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\llm.py:111\u001b[39m, in \u001b[36mget_completion\u001b[39m\u001b[34m(prompt, client, model_name, api_provider, temperature)\u001b[39m\n\u001b[32m    110\u001b[39m provider_module = ensure_provider(client, api_provider, model_name, \u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprovider_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\providers\\openai.py:127\u001b[39m, in \u001b[36mtext_completion\u001b[39m\u001b[34m(client, prompt, model_name, temperature)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pragma: no cover - network dependent\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderOperationError(\u001b[33m\"\u001b[39m\u001b[33mopenai\u001b[39m\u001b[33m\"\u001b[39m, model_name, \u001b[33m\"\u001b[39m\u001b[33mcompletion\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[31mProviderOperationError\u001b[39m: [openai:o3] completion error: Connection error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mProviderOperationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Generating SQL Schema ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prd_content:\n\u001b[32m     29\u001b[39m      \u001b[38;5;66;03m# Enhance the raw schema prompt using the project's prompt enhancer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m      enhanced_schema_prompt = \u001b[43mprompt_enhancer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m      \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSchema Enhanced prompt\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, enhanced_schema_prompt)\n\u001b[32m     33\u001b[39m      \u001b[38;5;66;03m# Send the enhanced prompt to the schema-specific LLM client\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\aiswe\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\utils\\llm.py:518\u001b[39m, in \u001b[36mprompt_enhancer\u001b[39m\u001b[34m(user_input, model_name, client, api_provider)\u001b[39m\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m enhanced_prompt.strip()\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ProviderOperationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ProviderOperationError(e.provider, e.model, \u001b[33m\"\u001b[39m\u001b[33mprompt enhancement\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    520\u001b[39m     prov = api_provider \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m().get(\u001b[33m\"\u001b[39m\u001b[33mprovider\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mProviderOperationError\u001b[39m: [openai:o3] prompt enhancement error: [openai:o3] completion error: Connection error."
     ]
    }
   ],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a senior Database Administrator. Based on the provided PRD context below, generate a complete SQL \n",
    "schema that is fully compatible with SQLite.\n",
    "\n",
    "Requirements:\n",
    "- Output only valid SQLite DDL statements (e.g., CREATE TABLE, CREATE INDEX). Do NOT include any surrounding markdown, commentary, or explanation; output raw SQL only.\n",
    "- Use SQLite data types and conventions: INTEGER, TEXT, REAL, BLOB, NUMERIC. For auto-incrementing primary keys use `INTEGER PRIMARY KEY AUTOINCREMENT`.\n",
    "- Do NOT use PostgreSQL/MySQL-specific types or keywords such as SERIAL, BIGSERIAL, AUTO_INCREMENT, or `ENGINE=` options.\n",
    "- Avoid features unsupported by SQLite (e.g., ALTER TABLE ... DROP COLUMN, advanced index types). Keep the DDL runnable by SQLite's `sqlite3` and via Python's `cursor.executescript()`.\n",
    "- Include sensible NOT NULL, UNIQUE constraints and FOREIGN KEY clauses where appropriate. Note: application must enable foreign key enforcement via `PRAGMA foreign_keys = ON`.\n",
    "- Produce CREATE INDEX statements for columns frequently used in WHERE or JOIN clauses if helpful.\n",
    "- Ensure the output is a single SQL script with statements separated by semicolons.\n",
    "\n",
    "PRD CONTEXT:\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "Now generate the SQLite-compatible SQL schema.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    try:\n",
    "        try:\n",
    "            enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "            print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"Prompt enhancement failed ({e}); falling back to original prompt.\")\n",
    "            enhanced_schema_prompt = schema_prompt\n",
    "\n",
    "        try:\n",
    "            generated_schema = get_completion(enhanced_schema_prompt, schema_client, schema_model_name, schema_api_provider)\n",
    "        except Exception as e:\n",
    "            print(f\"Schema generation failed ({e}). Aborting schema creation.\")\n",
    "            generated_schema = \"\"\n",
    "\n",
    "        cleaned_schema = clean_llm_output(generated_schema, language='sql') if generated_schema else \"\"\n",
    "        if cleaned_schema:\n",
    "            print(cleaned_schema)\n",
    "            save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "        else:\n",
    "            print(\"No schema produced.\")\n",
    "    finally:\n",
    "        # Ensure variable exists for downstream cells\n",
    "        cleaned_schema = cleaned_schema if 'cleaned_schema' in locals() else \"\"\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Generating Realistic Seed Data\n",
    "\n",
    "**Explanation:**\n",
    "An empty database isn't very useful for development. In Step 2 we generated a SQLite schema and saved it to `artifacts/schema.sql` (and the cleaned SQL is available in the `cleaned_schema` variable).\n",
    "\n",
    "This step asks the LLM to produce realistic, referentially-consistent seed data as raw SQL `INSERT` statements that can be executed against that schema. The seed data generator MUST:\n",
    "\n",
    "- Inspect the provided SQL schema (the `<schema>` block below and `artifacts/schema.sql`) and use the exact table and column names from it.\n",
    "- Respect column types, `NOT NULL` and `UNIQUE` constraints, and any `FOREIGN KEY` relationships declared in the schema. If a primary key is defined as `INTEGER PRIMARY KEY AUTOINCREMENT`, the model may insert `NULL` for the PK and then reference the assigned PK values consistently for foreign keys, or insert explicit numeric IDs â€” but all foreign key references must remain valid within the generated script.\n",
    "- Wrap the generated inserts in a transaction (for example, `BEGIN; ... COMMIT;`) to ensure atomic seeding and easier rollback during development.\n",
    "- Output only raw SQL (no markdown fences or explanatory text).\n",
    "- Provide realistic, non-sensitive sample values (plausible names, emails, dates, statuses) that match the project's PRD context.\n",
    "\n",
    "The notebook will save the cleaned SQL to `artifacts/seed_data.sql` and then apply it to the database file in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 09:51:22,336 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed Data Enhanced prompt\n",
      " <prompt>\n",
      "  <persona>\n",
      "    You are a senior database engineer and data-seeding specialist with expert knowledge of SQL, relationalâ€data integrity, and realistic test-data generation.\n",
      "  </persona>\n",
      "\n",
      "  <context>\n",
      "    1. Product domain: â€œTalentSphere AIâ€ â€“ an internal talentâ€mobility platform for Project Managers, HR partners, and Team Leads.  \n",
      "    2. Functional expectations (selected from PRD): user/manager onboarding, employee profiles, skills, projects, performance reviews, AI conversations, etc.  \n",
      "    3. Exact database schema (SQLite dialect, copied verbatim below).  \n",
      "       <schema>\n",
      "CREATE TABLE departments (\n",
      "    department_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now'))\n",
      ");\n",
      "CREATE TABLE employees (\n",
      "    employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    first_name TEXT NOT NULL,\n",
      "    last_name TEXT NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    job_title TEXT NOT NULL,\n",
      "    department_id INTEGER NOT NULL,\n",
      "    manager_id INTEGER,\n",
      "    hire_date TEXT NOT NULL,\n",
      "    is_demo_data INTEGER NOT NULL DEFAULT 0,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (department_id) REFERENCES departments(department_id) ON DELETE RESTRICT,\n",
      "    FOREIGN KEY (manager_id) REFERENCES employees(employee_id) ON DELETE SET NULL\n",
      ");\n",
      "CREATE TABLE users (\n",
      "    user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL UNIQUE,\n",
      "    sso_subject_id TEXT NOT NULL UNIQUE,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE roles (\n",
      "    role_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    role_name TEXT NOT NULL UNIQUE\n",
      ");\n",
      "CREATE TABLE user_roles (\n",
      "    user_id INTEGER NOT NULL,\n",
      "    role_id INTEGER NOT NULL,\n",
      "    PRIMARY KEY (user_id, role_id),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE skills (\n",
      "    skill_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    category TEXT,\n",
      "    description TEXT\n",
      ");\n",
      "CREATE TABLE employee_skills (\n",
      "    employee_skill_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    skill_id INTEGER NOT NULL,\n",
      "    proficiency_level INTEGER NOT NULL CHECK (proficiency_level BETWEEN 1 AND 5),\n",
      "    is_validated INTEGER NOT NULL DEFAULT 0,\n",
      "    last_updated TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    UNIQUE (employee_id, skill_id),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (skill_id) REFERENCES skills(skill_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE projects (\n",
      "    project_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    status TEXT NOT NULL DEFAULT 'PLANNED' CHECK (status IN ('PLANNED', 'ACTIVE', 'COMPLETED', 'ON_HOLD')),\n",
      "    start_date TEXT,\n",
      "    end_date TEXT,\n",
      "    owner_employee_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (owner_employee_id) REFERENCES employees(employee_id) ON DELETE SET NULL\n",
      ");\n",
      "CREATE TABLE project_employees (\n",
      "    project_employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    project_id INTEGER NOT NULL,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    role_on_project TEXT,\n",
      "    assigned_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    UNIQUE (project_id, employee_id),\n",
      "    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE metrics (\n",
      "    metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    description TEXT\n",
      ");\n",
      "CREATE TABLE performance_reviews (\n",
      "    review_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    reviewer_employee_id INTEGER NOT NULL,\n",
      "    review_period_start TEXT NOT NULL,\n",
      "    review_period_end TEXT NOT NULL,\n",
      "    overall_rating REAL CHECK (overall_rating BETWEEN 1.0 AND 5.0),\n",
      "    summary_strengths TEXT,\n",
      "    summary_areas_for_improvement TEXT,\n",
      "    submitted_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (reviewer_employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE review_metrics (\n",
      "    review_metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    review_id INTEGER NOT NULL,\n",
      "    metric_id INTEGER NOT NULL,\n",
      "    rating INTEGER NOT NULL CHECK (rating BETWEEN 1 AND 5),\n",
      "    comments TEXT,\n",
      "    UNIQUE (review_id, metric_id),\n",
      "    FOREIGN KEY (review_id) REFERENCES performance_reviews(review_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (metric_id) REFERENCES metrics(metric_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE conversations (\n",
      "    conversation_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    title TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE conversation_messages (\n",
      "    message_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    conversation_id INTEGER NOT NULL,\n",
      "    sender_type TEXT NOT NULL CHECK (sender_type IN ('USER', 'AI')),\n",
      "    message_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (conversation_id) REFERENCES conversations(conversation_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE project_comments (\n",
      "    comment_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    project_id INTEGER NOT NULL,\n",
      "    author_user_id INTEGER NOT NULL,\n",
      "    parent_comment_id INTEGER,\n",
      "    comment_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (author_user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (parent_comment_id) REFERENCES project_comments(comment_id) ON DELETE CASCADE\n",
      ");\n",
      "       </schema>\n",
      "    4. Practical data needs (derived from PRD):  \n",
      "       â€¢ At least 5 realistic Project Managers (with Users & role assignments)  \n",
      "       â€¢ At least 3 additional Employees (non-managers)  \n",
      "       â€¢ Departments, skills, projects, and onboarding / performance data to support demo scenarios.  \n",
      "       â€¢ 5â€Šâ€“â€Š10 INSERTs per major entity group to ensure a robust demo set.\n",
      "  </context>\n",
      "\n",
      "  <instructions>\n",
      "    1. Think step-by-step to draft internally consistent IDs and satisfy all PRIMARY KEY, UNIQUE, NOT NULL, CHECK, and FOREIGN KEY constraints.  \n",
      "    2. Wrap all seed data in a single transaction: begin with the literal line â€œBEGIN;â€ and end with â€œCOMMIT;â€.  \n",
      "    3. Use exact table and column names from the schema.  \n",
      "    4. Insert realistic ISO-8601 dates and plausible text values.  \n",
      "    5. If a column is defined as INTEGER PRIMARY KEY AUTOINCREMENT you may insert NULL and let SQLite assign the value, but you must reference the resulting IDs correctly in subsequent rows (use deterministic explicit IDs if simpler).  \n",
      "    6. Provide 5â€“10 INSERT statements per major entity group (departments, employees, users, roles, user_roles, skills, employee_skills, projects, project_employees, metrics, performance_reviews, review_metrics, optional conversations & messages, etc.).  \n",
      "    7. Include at least:  \n",
      "       â€¢ 5 project managers (have role â€œPROJECT_MANAGERâ€),  \n",
      "       â€¢ 3 employees without manager privileges,  \n",
      "       â€¢ Several onboarding / project assignments illustrating realistic relationships.  \n",
      "    8. Output strictly raw SQL onlyâ€”no comments, no Markdown, no explanatory text.\n",
      "  </instructions>\n",
      "\n",
      "  <output_format>\n",
      "    Raw SQL script beginning with â€œBEGIN;â€ and ending with â€œCOMMIT;â€. Each statement terminated with a semicolon.\n",
      "  </output_format>\n",
      "\n",
      "  <internal_note>\n",
      "    (Think through ID assignment, relationship integrity, and date coherence, but do NOT reveal this reasoning in the final answer.)\n",
      "  </internal_note>\n",
      "</prompt>\n",
      "BEGIN;\n",
      "\n",
      "-- departments\n",
      "INSERT INTO departments (department_id, name) VALUES\n",
      "(1, 'Engineering'),\n",
      "(2, 'Product Management'),\n",
      "(3, 'Human Resources'),\n",
      "(4, 'Design'),\n",
      "(5, 'Executive');\n",
      "\n",
      "-- roles\n",
      "INSERT INTO roles (role_id, role_name) VALUES\n",
      "(1, 'PROJECT_MANAGER'),\n",
      "(2, 'HR_PARTNER'),\n",
      "(3, 'TEAM_LEAD'),\n",
      "(4, 'EMPLOYEE');\n",
      "\n",
      "-- skills\n",
      "INSERT INTO skills (skill_id, name, category, description) VALUES\n",
      "(101, 'Python', 'Technical', 'Proficiency in Python programming language for backend development and data analysis.'),\n",
      "(102, 'SQL', 'Technical', 'Advanced knowledge of SQL for database management and querying.'),\n",
      "(103, 'Project Management', 'Management', 'Skills in planning, executing, and closing projects.'),\n",
      "(104, 'Agile Methodologies', 'Management', 'Experience with Scrum and Kanban frameworks.'),\n",
      "(105, 'User Experience (UX) Design', 'Design', 'Designing user-friendly interfaces and experiences.'),\n",
      "(106, 'Product Roadmapping', 'Product', 'Creating and managing product roadmaps.'),\n",
      "(107, 'Stakeholder Communication', 'Soft Skill', 'Effectively communicating with internal and external stakeholders.'),\n",
      "(108, 'Performance Management', 'HR', 'Managing and evaluating employee performance.'),\n",
      "(109, 'React', 'Technical', 'Building user interfaces with the React JavaScript library.'),\n",
      "(110, 'Data Visualization', 'Technical', 'Creating informative and aesthetic data visualizations.');\n",
      "\n",
      "-- metrics\n",
      "INSERT INTO metrics (metric_id, name, description) VALUES\n",
      "(201, 'Technical Proficiency', 'Demonstrates mastery of technical skills required for the role.'),\n",
      "(202, 'Communication', 'Effectively conveys information and ideas to others.'),\n",
      "(203, 'Teamwork & Collaboration', 'Works effectively with team members to achieve common goals.'),\n",
      "(204, 'Problem Solving', 'Identifies and resolves problems in a timely manner.'),\n",
      "(205, 'Project Delivery', 'Consistently delivers project milestones on time and within budget.');\n",
      "\n",
      "-- employees\n",
      "-- Top-level Executive\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(101, 'Aria', 'Chen', 'aria.chen@talentsphere.ai', 'Chief Executive Officer', 5, NULL, '2018-03-15', 1);\n",
      "-- Department Heads / Senior Managers\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(102, 'Ben', 'Carter', 'ben.carter@talentsphere.ai', 'VP of Engineering', 1, 101, '2019-01-20', 1),\n",
      "(103, 'Chloe', 'Davis', 'chloe.davis@talentsphere.ai', 'Director of Product', 2, 101, '2019-06-10', 1);\n",
      "-- Project Managers (5 total: 103, 104, 105, 106, 107)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(104, 'David', 'Evans', 'david.evans@talentsphere.ai', 'Senior Project Manager', 1, 102, '2020-02-11', 1),\n",
      "(105, 'Eva', 'Garcia', 'eva.garcia@talentsphere.ai', 'Project Manager', 1, 102, '2021-08-01', 1),\n",
      "(106, 'Frank', 'Harris', 'frank.harris@talentsphere.ai', 'Product Manager', 2, 103, '2020-09-05', 1),\n",
      "(107, 'Grace', 'Ivanov', 'grace.ivanov@talentsphere.ai', 'HR Business Partner', 3, 101, '2021-11-22', 1);\n",
      "-- Non-Manager Employees (4 total)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(108, 'Henry', 'Jones', 'henry.jones@talentsphere.ai', 'Senior Software Engineer', 1, 104, '2021-03-15', 1),\n",
      "(109, 'Isla', 'King', 'isla.king@talentsphere.ai', 'Software Engineer', 1, 105, '2022-07-18', 1),\n",
      "(110, 'Jack', 'Lee', 'jack.lee@talentsphere.ai', 'UX/UI Designer', 4, 103, '2022-01-10', 1),\n",
      "(111, 'Kara', 'Miller', 'kara.miller@talentsphere.ai', 'QA Engineer', 1, 105, '2023-05-30', 1);\n",
      "\n",
      "-- users\n",
      "INSERT INTO users (user_id, employee_id, sso_subject_id, is_active) VALUES\n",
      "(201, 101, 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 1),\n",
      "(202, 102, 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 1),\n",
      "(203, 103, 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 1),\n",
      "(204, 104, 'auth0|64f8a9b4c5d6e7f8a9bacbd2', 1),\n",
      "(205, 105, 'auth0|64f8a9b5c6d7e8f9a0baccd3', 1),\n",
      "(206, 106, 'auth0|64f8a9b6c7d8e9f0a1bbdced4', 1),\n",
      "(207, 107, 'auth0|64f8a9b7c8d9e0f1a2bbdded5', 1),\n",
      "(208, 108, 'auth0|64f8a9b8c9d0e1f2a3bcdeef6', 1),\n",
      "(209, 109, 'auth0|64f8a9b9c0d1e2f3a4bcfefg7', 1),\n",
      "(210, 110, 'auth0|64f8a9bac1d2e3f4a5bd0f0h8', 1),\n",
      "(211, 111, 'auth0|64f8a9bbd2e3f4a5b6e10f1i9', 1);\n",
      "\n",
      "-- user_roles\n",
      "-- Project Managers (Chloe Davis, David Evans, Eva Garcia, Frank Harris, Ben Carter)\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (202, 1), (203, 1), (204, 1), (205, 1), (206, 1);\n",
      "-- HR Partner\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (207, 2);\n",
      "-- Team Leads\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (204, 3), (205, 3);\n",
      "-- All are Employees\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (201, 4), (202, 4), (203, 4), (204, 4), (205, 4), (206, 4), (207, 4), (208, 4), (209, 4), (210, 4), (211, 4);\n",
      "\n",
      "-- employee_skills\n",
      "INSERT INTO employee_skills (employee_id, skill_id, proficiency_level, is_validated) VALUES\n",
      "(102, 103, 5, 1), (102, 104, 5, 1), (102, 107, 4, 1),\n",
      "(103, 103, 5, 1), (103, 106, 5, 1), (103, 107, 5, 1),\n",
      "(104, 103, 4, 1), (104, 104, 5, 1), (104, 102, 3, 0),\n",
      "(105, 103, 4, 1), (105, 104, 4, 0),\n",
      "(106, 106, 4, 1), (106, 105, 3, 0), (106, 107, 4, 1),\n",
      "(107, 108, 5, 1), (107, 107, 4, 1),\n",
      "(108, 101, 5, 1), (108, 102, 4, 1), (108, 109, 4, 1),\n",
      "(109, 101, 3, 1), (109, 109, 4, 0),\n",
      "(110, 105, 5, 1), (110, 110, 4, 1),\n",
      "(111, 101, 3, 0), (111, 102, 2, 0);\n",
      "\n",
      "-- projects\n",
      "INSERT INTO projects (project_id, name, description, status, start_date, end_date, owner_employee_id) VALUES\n",
      "(301, 'Q4 Platform Overhaul', 'A complete redesign and re-architecture of the main TalentSphere platform.', 'ACTIVE', '2023-10-01', '2023-12-31', 104),\n",
      "(302, 'AI Co-pilot Integration', 'Integrate a new generative AI assistant into the performance review module.', 'ACTIVE', '2023-11-15', '2024-02-28', 106),\n",
      "(303, 'Mobile App MVP', 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'PLANNED', '2024-01-10', '2024-04-30', 105),\n",
      "(304, '2023 Performance Review Cycle', 'Manage and execute the annual company-wide performance review cycle.', 'COMPLETED', '2023-07-01', '2023-08-31', 107),\n",
      "(305, 'Data Warehouse Migration', 'Migrate existing analytics data to a new cloud-based data warehouse solution.', 'ON_HOLD', '2023-09-01', '2024-01-15', 102);\n",
      "\n",
      "-- project_employees\n",
      "INSERT INTO project_employees (project_id, employee_id, role_on_project) VALUES\n",
      "(301, 104, 'Project Lead'), (301, 108, 'Lead Engineer'), (301, 109, 'Backend Engineer'), (301, 110, 'Lead Designer'),\n",
      "(302, 106, 'Product Lead'), (302, 108, 'AI/ML Engineer'), (302, 111, 'QA Lead'),\n",
      "(303, 105, 'Project Lead'), (303, 109, 'Mobile Engineer'), (303, 110, 'Mobile UX Designer'),\n",
      "(304, 107, 'HR Lead'), (304, 102, 'Executive Sponsor'), (304, 103, 'Executive Sponsor'),\n",
      "(301, 111, 'QA Engineer'), (302, 109, 'Backend Support');\n",
      "\n",
      "-- performance_reviews\n",
      "INSERT INTO performance_reviews (review_id, employee_id, reviewer_employee_id, review_period_start, review_period_end, overall_rating, summary_strengths, summary_areas_for_improvement) VALUES\n",
      "(401, 108, 104, '2023-01-01', '2023-06-30', 4.5, 'Henry consistently delivers high-quality code and is a go-to expert for complex backend issues. His work on the API refactor was exceptional.', 'Could be more proactive in sharing knowledge with junior team members and documenting complex systems.'),\n",
      "(402, 109, 105, '2023-01-01', '2023-06-30', 4.0, 'Isla has shown remarkable growth this period. She is a fast learner and has a great attitude. Her contributions to the Mobile App MVP have been significant.', 'Continue to build confidence in leading technical discussions and taking ownership of larger features.'),\n",
      "(403, 110, 103, '2023-01-01', '2023-06-30', 4.2, 'Jack''s design work is consistently excellent, intuitive, and user-centric. He collaborates effectively with both product and engineering.', 'Focus on developing data visualization skills to better present user research findings.');\n",
      "\n",
      "-- review_metrics\n",
      "INSERT INTO review_metrics (review_id, metric_id, rating, comments) VALUES\n",
      "(401, 201, 5, 'Top-tier technical skills in Python and system architecture.'),\n",
      "(401, 203, 4, 'Excellent collaborator within the core project team.'),\n",
      "(401, 204, 5, 'Highly effective at debugging and solving complex technical challenges.'),\n",
      "(402, 201, 4, 'Rapidly developing strong skills in React and mobile development.'),\n",
      "(402, 202, 3, 'Can be hesitant to speak up in larger meetings, but is very clear in 1-on-1s.'),\n",
      "(402, 203, 5, 'Always willing to help teammates and is a positive presence on the team.'),\n",
      "(403, 201, 5, 'Exceptional skill in UX/UI design principles and tools.'),\n",
      "(403, 202, 4, 'Clearly articulates design rationale and is receptive to feedback.');\n",
      "\n",
      "-- conversations\n",
      "INSERT INTO conversations (conversation_id, user_id, title) VALUES\n",
      "(501, 208, 'Career Path for Senior Engineer'),\n",
      "(502, 210, 'Project Brainstorming: Mobile App');\n",
      "\n",
      "-- conversation_messages\n",
      "INSERT INTO conversation_messages (conversation_id, sender_type, message_text) VALUES\n",
      "(501, 'USER', 'What are the typical career paths for a Senior Software Engineer at this company?'),\n",
      "(501, 'AI', 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'),\n",
      "(501, 'USER', 'Yes, tell me more about the skills for an Engineering Manager.'),\n",
      "(501, 'AI', 'To become an Engineering Manager, employees typically develop strong skills in Project Management, Performance Management, and Stakeholder Communication. Your manager, David Evans, is highly skilled in Project Management. You might consider asking him for mentorship opportunities.'),\n",
      "(502, 'USER', 'Help me brainstorm ideas for the new Mobile App MVP.'),\n",
      "(502, 'AI', 'Of course! The project goal is to create an MVP for iOS and Android. Based on similar successful projects, key features to consider are: 1. Employee Profile Viewing, 2. Skill Endorsements, 3. Project Directory Search, and 4. A simplified view of performance reviews. This aligns with the project description and leverages existing platform data.');\n",
      "\n",
      "-- project_comments\n",
      "INSERT INTO project_comments (comment_id, project_id, author_user_id, parent_comment_id, comment_text) VALUES\n",
      "(601, 301, 204, NULL, 'Team, let''s make sure we have the final architecture diagrams reviewed by EOD Friday. I''ve attached the latest version to the project docs.'),\n",
      "(602, 301, 208, 601, 'Sounds good, David. I''ve reviewed the diagrams and left a few comments regarding the database connection pooling strategy.'),\n",
      "(603, 301, 210, 601, 'From a design perspective, the new component library looks great. The handoff to engineering should be smooth.');\n",
      "\n",
      "COMMIT;\n",
      "BEGIN;\n",
      "\n",
      "-- departments\n",
      "INSERT INTO departments (department_id, name) VALUES\n",
      "(1, 'Engineering'),\n",
      "(2, 'Product Management'),\n",
      "(3, 'Human Resources'),\n",
      "(4, 'Design'),\n",
      "(5, 'Executive');\n",
      "\n",
      "-- roles\n",
      "INSERT INTO roles (role_id, role_name) VALUES\n",
      "(1, 'PROJECT_MANAGER'),\n",
      "(2, 'HR_PARTNER'),\n",
      "(3, 'TEAM_LEAD'),\n",
      "(4, 'EMPLOYEE');\n",
      "\n",
      "-- skills\n",
      "INSERT INTO skills (skill_id, name, category, description) VALUES\n",
      "(101, 'Python', 'Technical', 'Proficiency in Python programming language for backend development and data analysis.'),\n",
      "(102, 'SQL', 'Technical', 'Advanced knowledge of SQL for database management and querying.'),\n",
      "(103, 'Project Management', 'Management', 'Skills in planning, executing, and closing projects.'),\n",
      "(104, 'Agile Methodologies', 'Management', 'Experience with Scrum and Kanban frameworks.'),\n",
      "(105, 'User Experience (UX) Design', 'Design', 'Designing user-friendly interfaces and experiences.'),\n",
      "(106, 'Product Roadmapping', 'Product', 'Creating and managing product roadmaps.'),\n",
      "(107, 'Stakeholder Communication', 'Soft Skill', 'Effectively communicating with internal and external stakeholders.'),\n",
      "(108, 'Performance Management', 'HR', 'Managing and evaluating employee performance.'),\n",
      "(109, 'React', 'Technical', 'Building user interfaces with the React JavaScript library.'),\n",
      "(110, 'Data Visualization', 'Technical', 'Creating informative and aesthetic data visualizations.');\n",
      "\n",
      "-- metrics\n",
      "INSERT INTO metrics (metric_id, name, description) VALUES\n",
      "(201, 'Technical Proficiency', 'Demonstrates mastery of technical skills required for the role.'),\n",
      "(202, 'Communication', 'Effectively conveys information and ideas to others.'),\n",
      "(203, 'Teamwork & Collaboration', 'Works effectively with team members to achieve common goals.'),\n",
      "(204, 'Problem Solving', 'Identifies and resolves problems in a timely manner.'),\n",
      "(205, 'Project Delivery', 'Consistently delivers project milestones on time and within budget.');\n",
      "\n",
      "-- employees\n",
      "-- Top-level Executive\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(101, 'Aria', 'Chen', 'aria.chen@talentsphere.ai', 'Chief Executive Officer', 5, NULL, '2018-03-15', 1);\n",
      "-- Department Heads / Senior Managers\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(102, 'Ben', 'Carter', 'ben.carter@talentsphere.ai', 'VP of Engineering', 1, 101, '2019-01-20', 1),\n",
      "(103, 'Chloe', 'Davis', 'chloe.davis@talentsphere.ai', 'Director of Product', 2, 101, '2019-06-10', 1);\n",
      "-- Project Managers (5 total: 103, 104, 105, 106, 107)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(104, 'David', 'Evans', 'david.evans@talentsphere.ai', 'Senior Project Manager', 1, 102, '2020-02-11', 1),\n",
      "(105, 'Eva', 'Garcia', 'eva.garcia@talentsphere.ai', 'Project Manager', 1, 102, '2021-08-01', 1),\n",
      "(106, 'Frank', 'Harris', 'frank.harris@talentsphere.ai', 'Product Manager', 2, 103, '2020-09-05', 1),\n",
      "(107, 'Grace', 'Ivanov', 'grace.ivanov@talentsphere.ai', 'HR Business Partner', 3, 101, '2021-11-22', 1);\n",
      "-- Non-Manager Employees (4 total)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(108, 'Henry', 'Jones', 'henry.jones@talentsphere.ai', 'Senior Software Engineer', 1, 104, '2021-03-15', 1),\n",
      "(109, 'Isla', 'King', 'isla.king@talentsphere.ai', 'Software Engineer', 1, 105, '2022-07-18', 1),\n",
      "(110, 'Jack', 'Lee', 'jack.lee@talentsphere.ai', 'UX/UI Designer', 4, 103, '2022-01-10', 1),\n",
      "(111, 'Kara', 'Miller', 'kara.miller@talentsphere.ai', 'QA Engineer', 1, 105, '2023-05-30', 1);\n",
      "\n",
      "-- users\n",
      "INSERT INTO users (user_id, employee_id, sso_subject_id, is_active) VALUES\n",
      "(201, 101, 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 1),\n",
      "(202, 102, 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 1),\n",
      "(203, 103, 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 1),\n",
      "(204, 104, 'auth0|64f8a9b4c5d6e7f8a9bacbd2', 1),\n",
      "(205, 105, 'auth0|64f8a9b5c6d7e8f9a0baccd3', 1),\n",
      "(206, 106, 'auth0|64f8a9b6c7d8e9f0a1bbdced4', 1),\n",
      "(207, 107, 'auth0|64f8a9b7c8d9e0f1a2bbdded5', 1),\n",
      "(208, 108, 'auth0|64f8a9b8c9d0e1f2a3bcdeef6', 1),\n",
      "(209, 109, 'auth0|64f8a9b9c0d1e2f3a4bcfefg7', 1),\n",
      "(210, 110, 'auth0|64f8a9bac1d2e3f4a5bd0f0h8', 1),\n",
      "(211, 111, 'auth0|64f8a9bbd2e3f4a5b6e10f1i9', 1);\n",
      "\n",
      "-- user_roles\n",
      "-- Project Managers (Chloe Davis, David Evans, Eva Garcia, Frank Harris, Ben Carter)\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (202, 1), (203, 1), (204, 1), (205, 1), (206, 1);\n",
      "-- HR Partner\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (207, 2);\n",
      "-- Team Leads\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (204, 3), (205, 3);\n",
      "-- All are Employees\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (201, 4), (202, 4), (203, 4), (204, 4), (205, 4), (206, 4), (207, 4), (208, 4), (209, 4), (210, 4), (211, 4);\n",
      "\n",
      "-- employee_skills\n",
      "INSERT INTO employee_skills (employee_id, skill_id, proficiency_level, is_validated) VALUES\n",
      "(102, 103, 5, 1), (102, 104, 5, 1), (102, 107, 4, 1),\n",
      "(103, 103, 5, 1), (103, 106, 5, 1), (103, 107, 5, 1),\n",
      "(104, 103, 4, 1), (104, 104, 5, 1), (104, 102, 3, 0),\n",
      "(105, 103, 4, 1), (105, 104, 4, 0),\n",
      "(106, 106, 4, 1), (106, 105, 3, 0), (106, 107, 4, 1),\n",
      "(107, 108, 5, 1), (107, 107, 4, 1),\n",
      "(108, 101, 5, 1), (108, 102, 4, 1), (108, 109, 4, 1),\n",
      "(109, 101, 3, 1), (109, 109, 4, 0),\n",
      "(110, 105, 5, 1), (110, 110, 4, 1),\n",
      "(111, 101, 3, 0), (111, 102, 2, 0);\n",
      "\n",
      "-- projects\n",
      "INSERT INTO projects (project_id, name, description, status, start_date, end_date, owner_employee_id) VALUES\n",
      "(301, 'Q4 Platform Overhaul', 'A complete redesign and re-architecture of the main TalentSphere platform.', 'ACTIVE', '2023-10-01', '2023-12-31', 104),\n",
      "(302, 'AI Co-pilot Integration', 'Integrate a new generative AI assistant into the performance review module.', 'ACTIVE', '2023-11-15', '2024-02-28', 106),\n",
      "(303, 'Mobile App MVP', 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'PLANNED', '2024-01-10', '2024-04-30', 105),\n",
      "(304, '2023 Performance Review Cycle', 'Manage and execute the annual company-wide performance review cycle.', 'COMPLETED', '2023-07-01', '2023-08-31', 107),\n",
      "(305, 'Data Warehouse Migration', 'Migrate existing analytics data to a new cloud-based data warehouse solution.', 'ON_HOLD', '2023-09-01', '2024-01-15', 102);\n",
      "\n",
      "-- project_employees\n",
      "INSERT INTO project_employees (project_id, employee_id, role_on_project) VALUES\n",
      "(301, 104, 'Project Lead'), (301, 108, 'Lead Engineer'), (301, 109, 'Backend Engineer'), (301, 110, 'Lead Designer'),\n",
      "(302, 106, 'Product Lead'), (302, 108, 'AI/ML Engineer'), (302, 111, 'QA Lead'),\n",
      "(303, 105, 'Project Lead'), (303, 109, 'Mobile Engineer'), (303, 110, 'Mobile UX Designer'),\n",
      "(304, 107, 'HR Lead'), (304, 102, 'Executive Sponsor'), (304, 103, 'Executive Sponsor'),\n",
      "(301, 111, 'QA Engineer'), (302, 109, 'Backend Support');\n",
      "\n",
      "-- performance_reviews\n",
      "INSERT INTO performance_reviews (review_id, employee_id, reviewer_employee_id, review_period_start, review_period_end, overall_rating, summary_strengths, summary_areas_for_improvement) VALUES\n",
      "(401, 108, 104, '2023-01-01', '2023-06-30', 4.5, 'Henry consistently delivers high-quality code and is a go-to expert for complex backend issues. His work on the API refactor was exceptional.', 'Could be more proactive in sharing knowledge with junior team members and documenting complex systems.'),\n",
      "(402, 109, 105, '2023-01-01', '2023-06-30', 4.0, 'Isla has shown remarkable growth this period. She is a fast learner and has a great attitude. Her contributions to the Mobile App MVP have been significant.', 'Continue to build confidence in leading technical discussions and taking ownership of larger features.'),\n",
      "(403, 110, 103, '2023-01-01', '2023-06-30', 4.2, 'Jack''s design work is consistently excellent, intuitive, and user-centric. He collaborates effectively with both product and engineering.', 'Focus on developing data visualization skills to better present user research findings.');\n",
      "\n",
      "-- review_metrics\n",
      "INSERT INTO review_metrics (review_id, metric_id, rating, comments) VALUES\n",
      "(401, 201, 5, 'Top-tier technical skills in Python and system architecture.'),\n",
      "(401, 203, 4, 'Excellent collaborator within the core project team.'),\n",
      "(401, 204, 5, 'Highly effective at debugging and solving complex technical challenges.'),\n",
      "(402, 201, 4, 'Rapidly developing strong skills in React and mobile development.'),\n",
      "(402, 202, 3, 'Can be hesitant to speak up in larger meetings, but is very clear in 1-on-1s.'),\n",
      "(402, 203, 5, 'Always willing to help teammates and is a positive presence on the team.'),\n",
      "(403, 201, 5, 'Exceptional skill in UX/UI design principles and tools.'),\n",
      "(403, 202, 4, 'Clearly articulates design rationale and is receptive to feedback.');\n",
      "\n",
      "-- conversations\n",
      "INSERT INTO conversations (conversation_id, user_id, title) VALUES\n",
      "(501, 208, 'Career Path for Senior Engineer'),\n",
      "(502, 210, 'Project Brainstorming: Mobile App');\n",
      "\n",
      "-- conversation_messages\n",
      "INSERT INTO conversation_messages (conversation_id, sender_type, message_text) VALUES\n",
      "(501, 'USER', 'What are the typical career paths for a Senior Software Engineer at this company?'),\n",
      "(501, 'AI', 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'),\n",
      "(501, 'USER', 'Yes, tell me more about the skills for an Engineering Manager.'),\n",
      "(501, 'AI', 'To become an Engineering Manager, employees typically develop strong skills in Project Management, Performance Management, and Stakeholder Communication. Your manager, David Evans, is highly skilled in Project Management. You might consider asking him for mentorship opportunities.'),\n",
      "(502, 'USER', 'Help me brainstorm ideas for the new Mobile App MVP.'),\n",
      "(502, 'AI', 'Of course! The project goal is to create an MVP for iOS and Android. Based on similar successful projects, key features to consider are: 1. Employee Profile Viewing, 2. Skill Endorsements, 3. Project Directory Search, and 4. A simplified view of performance reviews. This aligns with the project description and leverages existing platform data.');\n",
      "\n",
      "-- project_comments\n",
      "INSERT INTO project_comments (comment_id, project_id, author_user_id, parent_comment_id, comment_text) VALUES\n",
      "(601, 301, 204, NULL, 'Team, let''s make sure we have the final architecture diagrams reviewed by EOD Friday. I''ve attached the latest version to the project docs.'),\n",
      "(602, 301, 208, 601, 'Sounds good, David. I''ve reviewed the diagrams and left a few comments regarding the database connection pooling strategy.'),\n",
      "(603, 301, 210, 601, 'From a design perspective, the new component library looks great. The handoff to engineering should be smooth.');\n",
      "\n",
      "COMMIT;\n"
     ]
    }
   ],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a data specialist. Based on the provided PRD and the exact SQL schema below, generate realistic SQL statements to seed the database for the onboarding tool.\n",
    "\n",
    "Requirements:\n",
    "- Inspect the provided SQL schema carefully (the `<schema>` block below and the file `artifacts/schema.sql`) and use the exact table and column names found there.\n",
    "- Produce a single SQL script that begins with `BEGIN;` and ends with `COMMIT;` to wrap all inserts in a transaction.\n",
    "- Ensure all `INSERT` statements respect column types, `NOT NULL` and `UNIQUE` constraints, and `FOREIGN KEY` relationships declared in the schema. If primary keys are `INTEGER PRIMARY KEY AUTOINCREMENT`, you may insert `NULL` for those columns and then reference the assigned values consistently for foreign keys, or insert explicit IDs â€” but relationships must be internally consistent.\n",
    "- Output only raw SQL (no markdown, no explanatory text).\n",
    "- Generate between 5 and 10 meaningful `INSERT` statements per major entity group (for example: users/project_managers/employees/applicants/onboarding_tasks) so the dataset is useful for development and testing.\n",
    "- Include at least 5 project managers and 3 employees, and a spread of onboarding tasks assigned to those users. Use realistic values for names, emails, dates (ISO 8601), and status fields consistent with the PRD.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "**SQL Schema:**\n",
    "<schema>\n",
    "{cleaned_schema}\n",
    "</schema>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    # Enhance the seed data prompt for better structure and fidelity\n",
    "    enhanced_seed_prompt = prompt_enhancer(seed_data_prompt)\n",
    "    print(\"Seed Data Enhanced prompt\\n\", enhanced_seed_prompt)\n",
    "\n",
    "    # Use the seed-data specific client\n",
    "    generated_seed_data = get_completion(enhanced_seed_prompt, seed_client, seed_model_name, seed_api_provider)\n",
    "\n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "\n",
    "    # Save the cleaned seed data to a file\n",
    "    save_artifact(cleaned_seed_data, \"artifacts/seed_data.sql\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Creating and Seeding a Live Database\n",
    "\n",
    "**Explanation:**\n",
    "This Python function demonstrates a crucial engineering task: turning text-based artifacts into a live system component. The `create_database` function uses Python's built-in `sqlite3` library.\n",
    "1.  It establishes a connection to a database file, which creates the file if it doesn't exist.\n",
    "2.  It reads the `schema.sql` artifact and executes it. It's important to use `cursor.executescript()` here. While `cursor.execute()` is designed for a single SQL statement, `executescript()` is necessary for running a string that contains multiple SQL statements, which is exactly what our `schema.sql` and `seed_data.sql` files contain.\n",
    "3.  It then reads and executes the `seed_data.sql` artifact to populate the newly created tables.\n",
    "4.  `conn.commit()` saves all the changes to the database file.\n",
    "5.  The `finally` block ensures that `conn.close()` is always called, which is a critical best practice to prevent resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to database at c:\\Users\\labadmin\\Documents\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\artifacts\\main_database.db\n",
      "Tables created successfully.\n",
      "Seed data inserted successfully.\n",
      "Database changes committed.\n",
      "Tables created successfully.\n",
      "Seed data inserted successfully.\n",
      "Database changes committed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "\n",
    "    # Delete the old database file if it exists to start fresh\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "        print(f\"Removed existing database file at {db_path}\")\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        # Enable foreign key enforcement for this connection\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read and execute the schema file\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if schema_sql:\n",
    "            cursor.executescript(schema_sql)\n",
    "            print(\"Tables created successfully.\")\n",
    "\n",
    "        # Read and execute the seed data file if it exists\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted successfully.\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(os.getcwd(), \"artifacts\", \"main_database.db\")\n",
    "schema_file = os.path.join(os.getcwd(), \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(os.getcwd(), \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function to create and seed the database\n",
    "create_database(db_file, schema_file, seed_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Verify the database was created successfully by querying the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database at c:\\Users\\labadmin\\Documents\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\artifacts\\main_database.db\n",
      "Table 'departments' contains 5 records\n",
      "--- Sample rows from departments ---\n",
      "{'department_id': 1, 'name': 'Engineering', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'department_id': 2, 'name': 'Product Management', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'department_id': 3, 'name': 'Human Resources', 'created_at': '2025-11-06 14:52:54'}\n",
      "Table 'employees' contains 11 records\n",
      "--- Sample rows from employees ---\n",
      "{'employee_id': 101, 'first_name': 'Aria', 'last_name': 'Chen', 'email': 'aria.chen@talentsphere.ai'}\n",
      "{'employee_id': 102, 'first_name': 'Ben', 'last_name': 'Carter', 'email': 'ben.carter@talentsphere.ai'}\n",
      "{'employee_id': 103, 'first_name': 'Chloe', 'last_name': 'Davis', 'email': 'chloe.davis@talentsphere.ai'}\n",
      "Table 'users' contains 11 records\n",
      "--- Sample rows from users ---\n",
      "{'user_id': 201, 'employee_id': 101, 'sso_subject_id': 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 'is_active': 1}\n",
      "{'user_id': 202, 'employee_id': 102, 'sso_subject_id': 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 'is_active': 1}\n",
      "{'user_id': 203, 'employee_id': 103, 'sso_subject_id': 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 'is_active': 1}\n",
      "Table 'roles' contains 4 records\n",
      "--- Sample rows from roles ---\n",
      "{'role_id': 1, 'role_name': 'PROJECT_MANAGER'}\n",
      "{'role_id': 2, 'role_name': 'HR_PARTNER'}\n",
      "{'role_id': 3, 'role_name': 'TEAM_LEAD'}\n",
      "Table 'user_roles' contains 19 records\n",
      "--- Sample rows from user_roles ---\n",
      "{'user_id': 202, 'role_id': 1}\n",
      "{'user_id': 203, 'role_id': 1}\n",
      "{'user_id': 204, 'role_id': 1}\n",
      "Table 'skills' contains 10 records\n",
      "--- Sample rows from skills ---\n",
      "{'skill_id': 101, 'name': 'Python', 'category': 'Technical', 'description': 'Proficiency in Python programming language for backend development and data analysis.'}\n",
      "{'skill_id': 102, 'name': 'SQL', 'category': 'Technical', 'description': 'Advanced knowledge of SQL for database management and querying.'}\n",
      "{'skill_id': 103, 'name': 'Project Management', 'category': 'Management', 'description': 'Skills in planning, executing, and closing projects.'}\n",
      "Table 'employee_skills' contains 25 records\n",
      "--- Sample rows from employee_skills ---\n",
      "{'employee_skill_id': 1, 'employee_id': 102, 'skill_id': 103, 'proficiency_level': 5}\n",
      "{'employee_skill_id': 2, 'employee_id': 102, 'skill_id': 104, 'proficiency_level': 5}\n",
      "{'employee_skill_id': 3, 'employee_id': 102, 'skill_id': 107, 'proficiency_level': 4}\n",
      "Table 'projects' contains 5 records\n",
      "--- Sample rows from projects ---\n",
      "{'project_id': 301, 'name': 'Q4 Platform Overhaul', 'description': 'A complete redesign and re-architecture of the main TalentSphere platform.', 'status': 'ACTIVE'}\n",
      "{'project_id': 302, 'name': 'AI Co-pilot Integration', 'description': 'Integrate a new generative AI assistant into the performance review module.', 'status': 'ACTIVE'}\n",
      "{'project_id': 303, 'name': 'Mobile App MVP', 'description': 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'status': 'PLANNED'}\n",
      "Table 'project_employees' contains 15 records\n",
      "--- Sample rows from project_employees ---\n",
      "{'project_employee_id': 1, 'project_id': 301, 'employee_id': 104, 'role_on_project': 'Project Lead'}\n",
      "{'project_employee_id': 2, 'project_id': 301, 'employee_id': 108, 'role_on_project': 'Lead Engineer'}\n",
      "{'project_employee_id': 3, 'project_id': 301, 'employee_id': 109, 'role_on_project': 'Backend Engineer'}\n",
      "Table 'metrics' contains 5 records\n",
      "--- Sample rows from metrics ---\n",
      "{'metric_id': 201, 'name': 'Technical Proficiency', 'description': 'Demonstrates mastery of technical skills required for the role.'}\n",
      "{'metric_id': 202, 'name': 'Communication', 'description': 'Effectively conveys information and ideas to others.'}\n",
      "{'metric_id': 203, 'name': 'Teamwork & Collaboration', 'description': 'Works effectively with team members to achieve common goals.'}\n",
      "Table 'performance_reviews' contains 3 records\n",
      "--- Sample rows from performance_reviews ---\n",
      "{'review_id': 401, 'employee_id': 108, 'reviewer_employee_id': 104, 'review_period_start': '2023-01-01'}\n",
      "{'review_id': 402, 'employee_id': 109, 'reviewer_employee_id': 105, 'review_period_start': '2023-01-01'}\n",
      "{'review_id': 403, 'employee_id': 110, 'reviewer_employee_id': 103, 'review_period_start': '2023-01-01'}\n",
      "Table 'review_metrics' contains 8 records\n",
      "--- Sample rows from review_metrics ---\n",
      "{'review_metric_id': 1, 'review_id': 401, 'metric_id': 201, 'rating': 5}\n",
      "{'review_metric_id': 2, 'review_id': 401, 'metric_id': 203, 'rating': 4}\n",
      "{'review_metric_id': 3, 'review_id': 401, 'metric_id': 204, 'rating': 5}\n",
      "Table 'conversations' contains 2 records\n",
      "--- Sample rows from conversations ---\n",
      "{'conversation_id': 501, 'user_id': 208, 'title': 'Career Path for Senior Engineer', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'conversation_id': 502, 'user_id': 210, 'title': 'Project Brainstorming: Mobile App', 'created_at': '2025-11-06 14:52:54'}\n",
      "Table 'conversation_messages' contains 6 records\n",
      "--- Sample rows from conversation_messages ---\n",
      "{'message_id': 1, 'conversation_id': 501, 'sender_type': 'USER', 'message_text': 'What are the typical career paths for a Senior Software Engineer at this company?'}\n",
      "{'message_id': 2, 'conversation_id': 501, 'sender_type': 'AI', 'message_text': 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'}\n",
      "{'message_id': 3, 'conversation_id': 501, 'sender_type': 'USER', 'message_text': 'Yes, tell me more about the skills for an Engineering Manager.'}\n",
      "Table 'project_comments' contains 3 records\n",
      "--- Sample rows from project_comments ---\n",
      "{'comment_id': 601, 'project_id': 301, 'author_user_id': 204, 'parent_comment_id': None}\n",
      "{'comment_id': 602, 'project_id': 301, 'author_user_id': 208, 'parent_comment_id': 601}\n",
      "{'comment_id': 603, 'project_id': 301, 'author_user_id': 210, 'parent_comment_id': 601}\n"
     ]
    }
   ],
   "source": [
    "# Verify the database was created successfully by querying the data\n",
    "def verify_database(db_path, schema_path=None):\n",
    "    \"\"\"Verify the database contains the expected data based on the generated schema.\"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Database file not found at {db_path}\")\n",
    "        return\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        # Ensure foreign keys are enforced for verification queries\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Connected to database at {db_path}\")\n",
    "\n",
    "        # Determine expected tables from the provided schema if available\n",
    "        schema_sql = \"\"\n",
    "        if schema_path and os.path.exists(schema_path):\n",
    "            schema_sql = load_artifact(schema_path) or \"\"\n",
    "        elif 'cleaned_schema' in globals() and cleaned_schema:\n",
    "            schema_sql = cleaned_schema\n",
    "\n",
    "        table_names = []\n",
    "        if schema_sql:\n",
    "            import re\n",
    "            # Extract table names from CREATE TABLE statements\n",
    "            matches = re.findall(r'CREATE\\s+TABLE\\s+(?:IF\\s+NOT\\s+EXISTS\\s+)?[\"`]?(\\w+)[\"`]?', schema_sql, flags=re.IGNORECASE)\n",
    "            table_names = list(dict.fromkeys(matches))  # preserve order, remove duplicates\n",
    "\n",
    "        # Fallback to common expected tables if schema parsing found nothing\n",
    "        if not table_names:\n",
    "            table_names = ['users', 'applicants', 'onboarding_tasks']\n",
    "\n",
    "        # Query each table for counts and a small sample of rows\n",
    "        for t in table_names:\n",
    "            try:\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {t}\")\n",
    "                count = cursor.fetchone()[0]\n",
    "                print(f\"Table '{t}' contains {count} records\")\n",
    "\n",
    "                # Get column names to present a representative sample row as a dict\n",
    "                cursor.execute(f\"PRAGMA table_info({t})\")\n",
    "                cols = [r[1] for r in cursor.fetchall()]\n",
    "                if cols:\n",
    "                    sel_cols = cols[:4]  # limit number of displayed columns\n",
    "                    cursor.execute(f\"SELECT {', '.join(sel_cols)} FROM {t} LIMIT 3\")\n",
    "                    rows = cursor.fetchall()\n",
    "                    if rows:\n",
    "                        print(f\"--- Sample rows from {t} ---\")\n",
    "                        for row in rows:\n",
    "                            # Align values with column names for readability\n",
    "                            sample = dict(zip(sel_cols, row))\n",
    "                            print(sample)\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Could not query table {t}: {e}\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Verify the database using the generated schema when available\n",
    "verify_database(db_file, schema_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
