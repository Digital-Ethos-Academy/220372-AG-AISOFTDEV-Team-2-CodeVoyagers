{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "We load the `day1_prd.md` artifact from Day 1. This document is the single source of truth for our project's requirements and provides the essential context for the LLM to generate a relevant and accurate database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\labadmin\\Documents\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\n",
      "Project root directory: c:\\Users\\labadmin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 09:54:03,208 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "2025-11-06 09:54:04,240 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "2025-11-06 09:54:04,240 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, recommended_models_table, prompt_enhancer\n",
    "\n",
    "# Initialize separate LLM clients for different artifacts to use the latest models from different providers.\n",
    "# - Schema generation uses a strong instruction-following model\n",
    "# - Seed data generation uses a model tuned for data generation\n",
    "schema_client, schema_model_name, schema_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "seed_client, seed_model_name, seed_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD\n",
    "prd_content = load_artifact(\"artifacts/project_prd.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load prd_content = artifacts/project_prd.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 - Generating the SQL Schema (SQLite)\n",
    "\n",
    "**Explanation:**\n",
    "This prompt instructs the LLM to act as a Database Administrator (DBA) and generate a SQL schema specifically compatible with SQLite.\n",
    "\n",
    "Guidance for the LLM and the developer:\n",
    "- Output only `CREATE TABLE` statements and associated `CREATE INDEX` statements where helpful. Do not include any surrounding markdown fences or explanatory text in the SQL output.\n",
    "- Use SQLite-compatible types and conventions: prefer `INTEGER`, `TEXT`, `REAL`, `BLOB`, and `NUMERIC`. For auto-incrementing primary keys use `INTEGER PRIMARY KEY AUTOINCREMENT`. Do NOT use `SERIAL`, `BIGSERIAL`, `AUTO_INCREMENT`, or PostgreSQL/MySQL-specific types or DDL.\n",
    "- Avoid features not supported by SQLite such as `ALTER TABLE ... DROP COLUMN`, `CHECK` constraints that reference subqueries, or advanced index types. Keep DDL portable for SQLite's capabilities.\n",
    "- Use `FOREIGN KEY` clauses only where appropriate; remember that SQLite enforces foreign keys only when `PRAGMA foreign_keys = ON` is set by the application.\n",
    "- Provide sensible column constraints (`NOT NULL`, `UNIQUE`) and default values using SQLite-supported expressions.\n",
    "\n",
    "We will post-process the LLM response with `clean_llm_output(..., language='sql')` to strip markdown and save the pure SQL to `artifacts/schema.sql`. The notebook later uses `cursor.executescript()` to run the SQL, so ensure the output is a single SQL script containing multiple statements separated by semicolons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating SQL Schema ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 09:54:04,658 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a senior Database Administrator. Based on the provided PRD context below, generate a complete SQL \n",
    "schema that is fully compatible with SQLite.\n",
    "\n",
    "Requirements:\n",
    "- Output only valid SQLite DDL statements (e.g., CREATE TABLE, CREATE INDEX). Do NOT include any surrounding markdown, commentary, or explanation; output raw SQL only.\n",
    "- Use SQLite data types and conventions: INTEGER, TEXT, REAL, BLOB, NUMERIC. For auto-incrementing primary keys use `INTEGER PRIMARY KEY AUTOINCREMENT`.\n",
    "- Do NOT use PostgreSQL/MySQL-specific types or keywords such as SERIAL, BIGSERIAL, AUTO_INCREMENT, or `ENGINE=` options.\n",
    "- Avoid features unsupported by SQLite (e.g., ALTER TABLE ... DROP COLUMN, advanced index types). Keep the DDL runnable by SQLite's `sqlite3` and via Python's `cursor.executescript()`.\n",
    "- Include sensible NOT NULL, UNIQUE constraints and FOREIGN KEY clauses where appropriate. Note: application must enable foreign key enforcement via `PRAGMA foreign_keys = ON`.\n",
    "- Produce CREATE INDEX statements for columns frequently used in WHERE or JOIN clauses if helpful.\n",
    "- Ensure the output is a single SQL script with statements separated by semicolons.\n",
    "\n",
    "PRD CONTEXT:\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "Now generate the SQLite-compatible SQL schema.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "     # Enhance the raw schema prompt using the project's prompt enhancer\n",
    "     enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "     print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "\n",
    "     # Send the enhanced prompt to the schema-specific LLM client\n",
    "     generated_schema = get_completion(enhanced_schema_prompt, schema_client, schema_model_name, schema_api_provider)\n",
    "\n",
    "     # Clean up the generated schema\n",
    "     cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "     print(cleaned_schema)\n",
    "\n",
    "     # Save the cleaned schema to a file\n",
    "     save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "else:\n",
    "     print(\"Skipping schema generation because PRD is missing.\")\n",
    "     cleaned_schema = \"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    # Enhance the raw schema prompt using the project's prompt enhancer\n",
    "    enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "    print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "\n",
    "    # Send the enhanced prompt to the schema-specific LLM client\n",
    "    generated_schema = get_completion(enhanced_schema_prompt, schema_client, schema_model_name, schema_api_provider)\n",
    "\n",
    "    # Clean up the generated schema\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "\n",
    "    # Save the cleaned schema to a file\n",
    "    save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Generating Realistic Seed Data\n",
    "\n",
    "**Explanation:**\n",
    "An empty database isn't very useful for development. In Step 2 we generated a SQLite schema and saved it to `artifacts/schema.sql` (and the cleaned SQL is available in the `cleaned_schema` variable).\n",
    "\n",
    "This step asks the LLM to produce realistic, referentially-consistent seed data as raw SQL `INSERT` statements that can be executed against that schema. The seed data generator MUST:\n",
    "\n",
    "- Inspect the provided SQL schema (the `<schema>` block below and `artifacts/schema.sql`) and use the exact table and column names from it.\n",
    "- Respect column types, `NOT NULL` and `UNIQUE` constraints, and any `FOREIGN KEY` relationships declared in the schema. If a primary key is defined as `INTEGER PRIMARY KEY AUTOINCREMENT`, the model may insert `NULL` for the PK and then reference the assigned PK values consistently for foreign keys, or insert explicit numeric IDs — but all foreign key references must remain valid within the generated script.\n",
    "- Wrap the generated inserts in a transaction (for example, `BEGIN; ... COMMIT;`) to ensure atomic seeding and easier rollback during development.\n",
    "- Output only raw SQL (no markdown fences or explanatory text).\n",
    "- Provide realistic, non-sensitive sample values (plausible names, emails, dates, statuses) that match the project's PRD context.\n",
    "\n",
    "The notebook will save the cleaned SQL to `artifacts/seed_data.sql` and then apply it to the database file in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Seed Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 09:51:22,336 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=o3 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed Data Enhanced prompt\n",
      " <prompt>\n",
      "  <persona>\n",
      "    You are a senior database engineer and data-seeding specialist with expert knowledge of SQL, relational‐data integrity, and realistic test-data generation.\n",
      "  </persona>\n",
      "\n",
      "  <context>\n",
      "    1. Product domain: “TalentSphere AI” – an internal talent‐mobility platform for Project Managers, HR partners, and Team Leads.  \n",
      "    2. Functional expectations (selected from PRD): user/manager onboarding, employee profiles, skills, projects, performance reviews, AI conversations, etc.  \n",
      "    3. Exact database schema (SQLite dialect, copied verbatim below).  \n",
      "       <schema>\n",
      "CREATE TABLE departments (\n",
      "    department_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now'))\n",
      ");\n",
      "CREATE TABLE employees (\n",
      "    employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    first_name TEXT NOT NULL,\n",
      "    last_name TEXT NOT NULL,\n",
      "    email TEXT NOT NULL UNIQUE,\n",
      "    job_title TEXT NOT NULL,\n",
      "    department_id INTEGER NOT NULL,\n",
      "    manager_id INTEGER,\n",
      "    hire_date TEXT NOT NULL,\n",
      "    is_demo_data INTEGER NOT NULL DEFAULT 0,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (department_id) REFERENCES departments(department_id) ON DELETE RESTRICT,\n",
      "    FOREIGN KEY (manager_id) REFERENCES employees(employee_id) ON DELETE SET NULL\n",
      ");\n",
      "CREATE TABLE users (\n",
      "    user_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL UNIQUE,\n",
      "    sso_subject_id TEXT NOT NULL UNIQUE,\n",
      "    is_active INTEGER NOT NULL DEFAULT 1,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE roles (\n",
      "    role_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    role_name TEXT NOT NULL UNIQUE\n",
      ");\n",
      "CREATE TABLE user_roles (\n",
      "    user_id INTEGER NOT NULL,\n",
      "    role_id INTEGER NOT NULL,\n",
      "    PRIMARY KEY (user_id, role_id),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (role_id) REFERENCES roles(role_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE skills (\n",
      "    skill_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    category TEXT,\n",
      "    description TEXT\n",
      ");\n",
      "CREATE TABLE employee_skills (\n",
      "    employee_skill_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    skill_id INTEGER NOT NULL,\n",
      "    proficiency_level INTEGER NOT NULL CHECK (proficiency_level BETWEEN 1 AND 5),\n",
      "    is_validated INTEGER NOT NULL DEFAULT 0,\n",
      "    last_updated TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    UNIQUE (employee_id, skill_id),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (skill_id) REFERENCES skills(skill_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE projects (\n",
      "    project_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL,\n",
      "    description TEXT,\n",
      "    status TEXT NOT NULL DEFAULT 'PLANNED' CHECK (status IN ('PLANNED', 'ACTIVE', 'COMPLETED', 'ON_HOLD')),\n",
      "    start_date TEXT,\n",
      "    end_date TEXT,\n",
      "    owner_employee_id INTEGER,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (owner_employee_id) REFERENCES employees(employee_id) ON DELETE SET NULL\n",
      ");\n",
      "CREATE TABLE project_employees (\n",
      "    project_employee_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    project_id INTEGER NOT NULL,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    role_on_project TEXT,\n",
      "    assigned_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    UNIQUE (project_id, employee_id),\n",
      "    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE metrics (\n",
      "    metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    name TEXT NOT NULL UNIQUE,\n",
      "    description TEXT\n",
      ");\n",
      "CREATE TABLE performance_reviews (\n",
      "    review_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    employee_id INTEGER NOT NULL,\n",
      "    reviewer_employee_id INTEGER NOT NULL,\n",
      "    review_period_start TEXT NOT NULL,\n",
      "    review_period_end TEXT NOT NULL,\n",
      "    overall_rating REAL CHECK (overall_rating BETWEEN 1.0 AND 5.0),\n",
      "    summary_strengths TEXT,\n",
      "    summary_areas_for_improvement TEXT,\n",
      "    submitted_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (reviewer_employee_id) REFERENCES employees(employee_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE review_metrics (\n",
      "    review_metric_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    review_id INTEGER NOT NULL,\n",
      "    metric_id INTEGER NOT NULL,\n",
      "    rating INTEGER NOT NULL CHECK (rating BETWEEN 1 AND 5),\n",
      "    comments TEXT,\n",
      "    UNIQUE (review_id, metric_id),\n",
      "    FOREIGN KEY (review_id) REFERENCES performance_reviews(review_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (metric_id) REFERENCES metrics(metric_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE conversations (\n",
      "    conversation_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    user_id INTEGER NOT NULL,\n",
      "    title TEXT,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE conversation_messages (\n",
      "    message_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    conversation_id INTEGER NOT NULL,\n",
      "    sender_type TEXT NOT NULL CHECK (sender_type IN ('USER', 'AI')),\n",
      "    message_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (conversation_id) REFERENCES conversations(conversation_id) ON DELETE CASCADE\n",
      ");\n",
      "CREATE TABLE project_comments (\n",
      "    comment_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
      "    project_id INTEGER NOT NULL,\n",
      "    author_user_id INTEGER NOT NULL,\n",
      "    parent_comment_id INTEGER,\n",
      "    comment_text TEXT NOT NULL,\n",
      "    created_at TEXT NOT NULL DEFAULT (datetime('now')),\n",
      "    FOREIGN KEY (project_id) REFERENCES projects(project_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (author_user_id) REFERENCES users(user_id) ON DELETE CASCADE,\n",
      "    FOREIGN KEY (parent_comment_id) REFERENCES project_comments(comment_id) ON DELETE CASCADE\n",
      ");\n",
      "       </schema>\n",
      "    4. Practical data needs (derived from PRD):  \n",
      "       • At least 5 realistic Project Managers (with Users & role assignments)  \n",
      "       • At least 3 additional Employees (non-managers)  \n",
      "       • Departments, skills, projects, and onboarding / performance data to support demo scenarios.  \n",
      "       • 5 – 10 INSERTs per major entity group to ensure a robust demo set.\n",
      "  </context>\n",
      "\n",
      "  <instructions>\n",
      "    1. Think step-by-step to draft internally consistent IDs and satisfy all PRIMARY KEY, UNIQUE, NOT NULL, CHECK, and FOREIGN KEY constraints.  \n",
      "    2. Wrap all seed data in a single transaction: begin with the literal line “BEGIN;” and end with “COMMIT;”.  \n",
      "    3. Use exact table and column names from the schema.  \n",
      "    4. Insert realistic ISO-8601 dates and plausible text values.  \n",
      "    5. If a column is defined as INTEGER PRIMARY KEY AUTOINCREMENT you may insert NULL and let SQLite assign the value, but you must reference the resulting IDs correctly in subsequent rows (use deterministic explicit IDs if simpler).  \n",
      "    6. Provide 5–10 INSERT statements per major entity group (departments, employees, users, roles, user_roles, skills, employee_skills, projects, project_employees, metrics, performance_reviews, review_metrics, optional conversations & messages, etc.).  \n",
      "    7. Include at least:  \n",
      "       • 5 project managers (have role “PROJECT_MANAGER”),  \n",
      "       • 3 employees without manager privileges,  \n",
      "       • Several onboarding / project assignments illustrating realistic relationships.  \n",
      "    8. Output strictly raw SQL only—no comments, no Markdown, no explanatory text.\n",
      "  </instructions>\n",
      "\n",
      "  <output_format>\n",
      "    Raw SQL script beginning with “BEGIN;” and ending with “COMMIT;”. Each statement terminated with a semicolon.\n",
      "  </output_format>\n",
      "\n",
      "  <internal_note>\n",
      "    (Think through ID assignment, relationship integrity, and date coherence, but do NOT reveal this reasoning in the final answer.)\n",
      "  </internal_note>\n",
      "</prompt>\n",
      "BEGIN;\n",
      "\n",
      "-- departments\n",
      "INSERT INTO departments (department_id, name) VALUES\n",
      "(1, 'Engineering'),\n",
      "(2, 'Product Management'),\n",
      "(3, 'Human Resources'),\n",
      "(4, 'Design'),\n",
      "(5, 'Executive');\n",
      "\n",
      "-- roles\n",
      "INSERT INTO roles (role_id, role_name) VALUES\n",
      "(1, 'PROJECT_MANAGER'),\n",
      "(2, 'HR_PARTNER'),\n",
      "(3, 'TEAM_LEAD'),\n",
      "(4, 'EMPLOYEE');\n",
      "\n",
      "-- skills\n",
      "INSERT INTO skills (skill_id, name, category, description) VALUES\n",
      "(101, 'Python', 'Technical', 'Proficiency in Python programming language for backend development and data analysis.'),\n",
      "(102, 'SQL', 'Technical', 'Advanced knowledge of SQL for database management and querying.'),\n",
      "(103, 'Project Management', 'Management', 'Skills in planning, executing, and closing projects.'),\n",
      "(104, 'Agile Methodologies', 'Management', 'Experience with Scrum and Kanban frameworks.'),\n",
      "(105, 'User Experience (UX) Design', 'Design', 'Designing user-friendly interfaces and experiences.'),\n",
      "(106, 'Product Roadmapping', 'Product', 'Creating and managing product roadmaps.'),\n",
      "(107, 'Stakeholder Communication', 'Soft Skill', 'Effectively communicating with internal and external stakeholders.'),\n",
      "(108, 'Performance Management', 'HR', 'Managing and evaluating employee performance.'),\n",
      "(109, 'React', 'Technical', 'Building user interfaces with the React JavaScript library.'),\n",
      "(110, 'Data Visualization', 'Technical', 'Creating informative and aesthetic data visualizations.');\n",
      "\n",
      "-- metrics\n",
      "INSERT INTO metrics (metric_id, name, description) VALUES\n",
      "(201, 'Technical Proficiency', 'Demonstrates mastery of technical skills required for the role.'),\n",
      "(202, 'Communication', 'Effectively conveys information and ideas to others.'),\n",
      "(203, 'Teamwork & Collaboration', 'Works effectively with team members to achieve common goals.'),\n",
      "(204, 'Problem Solving', 'Identifies and resolves problems in a timely manner.'),\n",
      "(205, 'Project Delivery', 'Consistently delivers project milestones on time and within budget.');\n",
      "\n",
      "-- employees\n",
      "-- Top-level Executive\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(101, 'Aria', 'Chen', 'aria.chen@talentsphere.ai', 'Chief Executive Officer', 5, NULL, '2018-03-15', 1);\n",
      "-- Department Heads / Senior Managers\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(102, 'Ben', 'Carter', 'ben.carter@talentsphere.ai', 'VP of Engineering', 1, 101, '2019-01-20', 1),\n",
      "(103, 'Chloe', 'Davis', 'chloe.davis@talentsphere.ai', 'Director of Product', 2, 101, '2019-06-10', 1);\n",
      "-- Project Managers (5 total: 103, 104, 105, 106, 107)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(104, 'David', 'Evans', 'david.evans@talentsphere.ai', 'Senior Project Manager', 1, 102, '2020-02-11', 1),\n",
      "(105, 'Eva', 'Garcia', 'eva.garcia@talentsphere.ai', 'Project Manager', 1, 102, '2021-08-01', 1),\n",
      "(106, 'Frank', 'Harris', 'frank.harris@talentsphere.ai', 'Product Manager', 2, 103, '2020-09-05', 1),\n",
      "(107, 'Grace', 'Ivanov', 'grace.ivanov@talentsphere.ai', 'HR Business Partner', 3, 101, '2021-11-22', 1);\n",
      "-- Non-Manager Employees (4 total)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(108, 'Henry', 'Jones', 'henry.jones@talentsphere.ai', 'Senior Software Engineer', 1, 104, '2021-03-15', 1),\n",
      "(109, 'Isla', 'King', 'isla.king@talentsphere.ai', 'Software Engineer', 1, 105, '2022-07-18', 1),\n",
      "(110, 'Jack', 'Lee', 'jack.lee@talentsphere.ai', 'UX/UI Designer', 4, 103, '2022-01-10', 1),\n",
      "(111, 'Kara', 'Miller', 'kara.miller@talentsphere.ai', 'QA Engineer', 1, 105, '2023-05-30', 1);\n",
      "\n",
      "-- users\n",
      "INSERT INTO users (user_id, employee_id, sso_subject_id, is_active) VALUES\n",
      "(201, 101, 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 1),\n",
      "(202, 102, 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 1),\n",
      "(203, 103, 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 1),\n",
      "(204, 104, 'auth0|64f8a9b4c5d6e7f8a9bacbd2', 1),\n",
      "(205, 105, 'auth0|64f8a9b5c6d7e8f9a0baccd3', 1),\n",
      "(206, 106, 'auth0|64f8a9b6c7d8e9f0a1bbdced4', 1),\n",
      "(207, 107, 'auth0|64f8a9b7c8d9e0f1a2bbdded5', 1),\n",
      "(208, 108, 'auth0|64f8a9b8c9d0e1f2a3bcdeef6', 1),\n",
      "(209, 109, 'auth0|64f8a9b9c0d1e2f3a4bcfefg7', 1),\n",
      "(210, 110, 'auth0|64f8a9bac1d2e3f4a5bd0f0h8', 1),\n",
      "(211, 111, 'auth0|64f8a9bbd2e3f4a5b6e10f1i9', 1);\n",
      "\n",
      "-- user_roles\n",
      "-- Project Managers (Chloe Davis, David Evans, Eva Garcia, Frank Harris, Ben Carter)\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (202, 1), (203, 1), (204, 1), (205, 1), (206, 1);\n",
      "-- HR Partner\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (207, 2);\n",
      "-- Team Leads\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (204, 3), (205, 3);\n",
      "-- All are Employees\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (201, 4), (202, 4), (203, 4), (204, 4), (205, 4), (206, 4), (207, 4), (208, 4), (209, 4), (210, 4), (211, 4);\n",
      "\n",
      "-- employee_skills\n",
      "INSERT INTO employee_skills (employee_id, skill_id, proficiency_level, is_validated) VALUES\n",
      "(102, 103, 5, 1), (102, 104, 5, 1), (102, 107, 4, 1),\n",
      "(103, 103, 5, 1), (103, 106, 5, 1), (103, 107, 5, 1),\n",
      "(104, 103, 4, 1), (104, 104, 5, 1), (104, 102, 3, 0),\n",
      "(105, 103, 4, 1), (105, 104, 4, 0),\n",
      "(106, 106, 4, 1), (106, 105, 3, 0), (106, 107, 4, 1),\n",
      "(107, 108, 5, 1), (107, 107, 4, 1),\n",
      "(108, 101, 5, 1), (108, 102, 4, 1), (108, 109, 4, 1),\n",
      "(109, 101, 3, 1), (109, 109, 4, 0),\n",
      "(110, 105, 5, 1), (110, 110, 4, 1),\n",
      "(111, 101, 3, 0), (111, 102, 2, 0);\n",
      "\n",
      "-- projects\n",
      "INSERT INTO projects (project_id, name, description, status, start_date, end_date, owner_employee_id) VALUES\n",
      "(301, 'Q4 Platform Overhaul', 'A complete redesign and re-architecture of the main TalentSphere platform.', 'ACTIVE', '2023-10-01', '2023-12-31', 104),\n",
      "(302, 'AI Co-pilot Integration', 'Integrate a new generative AI assistant into the performance review module.', 'ACTIVE', '2023-11-15', '2024-02-28', 106),\n",
      "(303, 'Mobile App MVP', 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'PLANNED', '2024-01-10', '2024-04-30', 105),\n",
      "(304, '2023 Performance Review Cycle', 'Manage and execute the annual company-wide performance review cycle.', 'COMPLETED', '2023-07-01', '2023-08-31', 107),\n",
      "(305, 'Data Warehouse Migration', 'Migrate existing analytics data to a new cloud-based data warehouse solution.', 'ON_HOLD', '2023-09-01', '2024-01-15', 102);\n",
      "\n",
      "-- project_employees\n",
      "INSERT INTO project_employees (project_id, employee_id, role_on_project) VALUES\n",
      "(301, 104, 'Project Lead'), (301, 108, 'Lead Engineer'), (301, 109, 'Backend Engineer'), (301, 110, 'Lead Designer'),\n",
      "(302, 106, 'Product Lead'), (302, 108, 'AI/ML Engineer'), (302, 111, 'QA Lead'),\n",
      "(303, 105, 'Project Lead'), (303, 109, 'Mobile Engineer'), (303, 110, 'Mobile UX Designer'),\n",
      "(304, 107, 'HR Lead'), (304, 102, 'Executive Sponsor'), (304, 103, 'Executive Sponsor'),\n",
      "(301, 111, 'QA Engineer'), (302, 109, 'Backend Support');\n",
      "\n",
      "-- performance_reviews\n",
      "INSERT INTO performance_reviews (review_id, employee_id, reviewer_employee_id, review_period_start, review_period_end, overall_rating, summary_strengths, summary_areas_for_improvement) VALUES\n",
      "(401, 108, 104, '2023-01-01', '2023-06-30', 4.5, 'Henry consistently delivers high-quality code and is a go-to expert for complex backend issues. His work on the API refactor was exceptional.', 'Could be more proactive in sharing knowledge with junior team members and documenting complex systems.'),\n",
      "(402, 109, 105, '2023-01-01', '2023-06-30', 4.0, 'Isla has shown remarkable growth this period. She is a fast learner and has a great attitude. Her contributions to the Mobile App MVP have been significant.', 'Continue to build confidence in leading technical discussions and taking ownership of larger features.'),\n",
      "(403, 110, 103, '2023-01-01', '2023-06-30', 4.2, 'Jack''s design work is consistently excellent, intuitive, and user-centric. He collaborates effectively with both product and engineering.', 'Focus on developing data visualization skills to better present user research findings.');\n",
      "\n",
      "-- review_metrics\n",
      "INSERT INTO review_metrics (review_id, metric_id, rating, comments) VALUES\n",
      "(401, 201, 5, 'Top-tier technical skills in Python and system architecture.'),\n",
      "(401, 203, 4, 'Excellent collaborator within the core project team.'),\n",
      "(401, 204, 5, 'Highly effective at debugging and solving complex technical challenges.'),\n",
      "(402, 201, 4, 'Rapidly developing strong skills in React and mobile development.'),\n",
      "(402, 202, 3, 'Can be hesitant to speak up in larger meetings, but is very clear in 1-on-1s.'),\n",
      "(402, 203, 5, 'Always willing to help teammates and is a positive presence on the team.'),\n",
      "(403, 201, 5, 'Exceptional skill in UX/UI design principles and tools.'),\n",
      "(403, 202, 4, 'Clearly articulates design rationale and is receptive to feedback.');\n",
      "\n",
      "-- conversations\n",
      "INSERT INTO conversations (conversation_id, user_id, title) VALUES\n",
      "(501, 208, 'Career Path for Senior Engineer'),\n",
      "(502, 210, 'Project Brainstorming: Mobile App');\n",
      "\n",
      "-- conversation_messages\n",
      "INSERT INTO conversation_messages (conversation_id, sender_type, message_text) VALUES\n",
      "(501, 'USER', 'What are the typical career paths for a Senior Software Engineer at this company?'),\n",
      "(501, 'AI', 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'),\n",
      "(501, 'USER', 'Yes, tell me more about the skills for an Engineering Manager.'),\n",
      "(501, 'AI', 'To become an Engineering Manager, employees typically develop strong skills in Project Management, Performance Management, and Stakeholder Communication. Your manager, David Evans, is highly skilled in Project Management. You might consider asking him for mentorship opportunities.'),\n",
      "(502, 'USER', 'Help me brainstorm ideas for the new Mobile App MVP.'),\n",
      "(502, 'AI', 'Of course! The project goal is to create an MVP for iOS and Android. Based on similar successful projects, key features to consider are: 1. Employee Profile Viewing, 2. Skill Endorsements, 3. Project Directory Search, and 4. A simplified view of performance reviews. This aligns with the project description and leverages existing platform data.');\n",
      "\n",
      "-- project_comments\n",
      "INSERT INTO project_comments (comment_id, project_id, author_user_id, parent_comment_id, comment_text) VALUES\n",
      "(601, 301, 204, NULL, 'Team, let''s make sure we have the final architecture diagrams reviewed by EOD Friday. I''ve attached the latest version to the project docs.'),\n",
      "(602, 301, 208, 601, 'Sounds good, David. I''ve reviewed the diagrams and left a few comments regarding the database connection pooling strategy.'),\n",
      "(603, 301, 210, 601, 'From a design perspective, the new component library looks great. The handoff to engineering should be smooth.');\n",
      "\n",
      "COMMIT;\n",
      "BEGIN;\n",
      "\n",
      "-- departments\n",
      "INSERT INTO departments (department_id, name) VALUES\n",
      "(1, 'Engineering'),\n",
      "(2, 'Product Management'),\n",
      "(3, 'Human Resources'),\n",
      "(4, 'Design'),\n",
      "(5, 'Executive');\n",
      "\n",
      "-- roles\n",
      "INSERT INTO roles (role_id, role_name) VALUES\n",
      "(1, 'PROJECT_MANAGER'),\n",
      "(2, 'HR_PARTNER'),\n",
      "(3, 'TEAM_LEAD'),\n",
      "(4, 'EMPLOYEE');\n",
      "\n",
      "-- skills\n",
      "INSERT INTO skills (skill_id, name, category, description) VALUES\n",
      "(101, 'Python', 'Technical', 'Proficiency in Python programming language for backend development and data analysis.'),\n",
      "(102, 'SQL', 'Technical', 'Advanced knowledge of SQL for database management and querying.'),\n",
      "(103, 'Project Management', 'Management', 'Skills in planning, executing, and closing projects.'),\n",
      "(104, 'Agile Methodologies', 'Management', 'Experience with Scrum and Kanban frameworks.'),\n",
      "(105, 'User Experience (UX) Design', 'Design', 'Designing user-friendly interfaces and experiences.'),\n",
      "(106, 'Product Roadmapping', 'Product', 'Creating and managing product roadmaps.'),\n",
      "(107, 'Stakeholder Communication', 'Soft Skill', 'Effectively communicating with internal and external stakeholders.'),\n",
      "(108, 'Performance Management', 'HR', 'Managing and evaluating employee performance.'),\n",
      "(109, 'React', 'Technical', 'Building user interfaces with the React JavaScript library.'),\n",
      "(110, 'Data Visualization', 'Technical', 'Creating informative and aesthetic data visualizations.');\n",
      "\n",
      "-- metrics\n",
      "INSERT INTO metrics (metric_id, name, description) VALUES\n",
      "(201, 'Technical Proficiency', 'Demonstrates mastery of technical skills required for the role.'),\n",
      "(202, 'Communication', 'Effectively conveys information and ideas to others.'),\n",
      "(203, 'Teamwork & Collaboration', 'Works effectively with team members to achieve common goals.'),\n",
      "(204, 'Problem Solving', 'Identifies and resolves problems in a timely manner.'),\n",
      "(205, 'Project Delivery', 'Consistently delivers project milestones on time and within budget.');\n",
      "\n",
      "-- employees\n",
      "-- Top-level Executive\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(101, 'Aria', 'Chen', 'aria.chen@talentsphere.ai', 'Chief Executive Officer', 5, NULL, '2018-03-15', 1);\n",
      "-- Department Heads / Senior Managers\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(102, 'Ben', 'Carter', 'ben.carter@talentsphere.ai', 'VP of Engineering', 1, 101, '2019-01-20', 1),\n",
      "(103, 'Chloe', 'Davis', 'chloe.davis@talentsphere.ai', 'Director of Product', 2, 101, '2019-06-10', 1);\n",
      "-- Project Managers (5 total: 103, 104, 105, 106, 107)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(104, 'David', 'Evans', 'david.evans@talentsphere.ai', 'Senior Project Manager', 1, 102, '2020-02-11', 1),\n",
      "(105, 'Eva', 'Garcia', 'eva.garcia@talentsphere.ai', 'Project Manager', 1, 102, '2021-08-01', 1),\n",
      "(106, 'Frank', 'Harris', 'frank.harris@talentsphere.ai', 'Product Manager', 2, 103, '2020-09-05', 1),\n",
      "(107, 'Grace', 'Ivanov', 'grace.ivanov@talentsphere.ai', 'HR Business Partner', 3, 101, '2021-11-22', 1);\n",
      "-- Non-Manager Employees (4 total)\n",
      "INSERT INTO employees (employee_id, first_name, last_name, email, job_title, department_id, manager_id, hire_date, is_demo_data) VALUES\n",
      "(108, 'Henry', 'Jones', 'henry.jones@talentsphere.ai', 'Senior Software Engineer', 1, 104, '2021-03-15', 1),\n",
      "(109, 'Isla', 'King', 'isla.king@talentsphere.ai', 'Software Engineer', 1, 105, '2022-07-18', 1),\n",
      "(110, 'Jack', 'Lee', 'jack.lee@talentsphere.ai', 'UX/UI Designer', 4, 103, '2022-01-10', 1),\n",
      "(111, 'Kara', 'Miller', 'kara.miller@talentsphere.ai', 'QA Engineer', 1, 105, '2023-05-30', 1);\n",
      "\n",
      "-- users\n",
      "INSERT INTO users (user_id, employee_id, sso_subject_id, is_active) VALUES\n",
      "(201, 101, 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 1),\n",
      "(202, 102, 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 1),\n",
      "(203, 103, 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 1),\n",
      "(204, 104, 'auth0|64f8a9b4c5d6e7f8a9bacbd2', 1),\n",
      "(205, 105, 'auth0|64f8a9b5c6d7e8f9a0baccd3', 1),\n",
      "(206, 106, 'auth0|64f8a9b6c7d8e9f0a1bbdced4', 1),\n",
      "(207, 107, 'auth0|64f8a9b7c8d9e0f1a2bbdded5', 1),\n",
      "(208, 108, 'auth0|64f8a9b8c9d0e1f2a3bcdeef6', 1),\n",
      "(209, 109, 'auth0|64f8a9b9c0d1e2f3a4bcfefg7', 1),\n",
      "(210, 110, 'auth0|64f8a9bac1d2e3f4a5bd0f0h8', 1),\n",
      "(211, 111, 'auth0|64f8a9bbd2e3f4a5b6e10f1i9', 1);\n",
      "\n",
      "-- user_roles\n",
      "-- Project Managers (Chloe Davis, David Evans, Eva Garcia, Frank Harris, Ben Carter)\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (202, 1), (203, 1), (204, 1), (205, 1), (206, 1);\n",
      "-- HR Partner\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (207, 2);\n",
      "-- Team Leads\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (204, 3), (205, 3);\n",
      "-- All are Employees\n",
      "INSERT INTO user_roles (user_id, role_id) VALUES (201, 4), (202, 4), (203, 4), (204, 4), (205, 4), (206, 4), (207, 4), (208, 4), (209, 4), (210, 4), (211, 4);\n",
      "\n",
      "-- employee_skills\n",
      "INSERT INTO employee_skills (employee_id, skill_id, proficiency_level, is_validated) VALUES\n",
      "(102, 103, 5, 1), (102, 104, 5, 1), (102, 107, 4, 1),\n",
      "(103, 103, 5, 1), (103, 106, 5, 1), (103, 107, 5, 1),\n",
      "(104, 103, 4, 1), (104, 104, 5, 1), (104, 102, 3, 0),\n",
      "(105, 103, 4, 1), (105, 104, 4, 0),\n",
      "(106, 106, 4, 1), (106, 105, 3, 0), (106, 107, 4, 1),\n",
      "(107, 108, 5, 1), (107, 107, 4, 1),\n",
      "(108, 101, 5, 1), (108, 102, 4, 1), (108, 109, 4, 1),\n",
      "(109, 101, 3, 1), (109, 109, 4, 0),\n",
      "(110, 105, 5, 1), (110, 110, 4, 1),\n",
      "(111, 101, 3, 0), (111, 102, 2, 0);\n",
      "\n",
      "-- projects\n",
      "INSERT INTO projects (project_id, name, description, status, start_date, end_date, owner_employee_id) VALUES\n",
      "(301, 'Q4 Platform Overhaul', 'A complete redesign and re-architecture of the main TalentSphere platform.', 'ACTIVE', '2023-10-01', '2023-12-31', 104),\n",
      "(302, 'AI Co-pilot Integration', 'Integrate a new generative AI assistant into the performance review module.', 'ACTIVE', '2023-11-15', '2024-02-28', 106),\n",
      "(303, 'Mobile App MVP', 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'PLANNED', '2024-01-10', '2024-04-30', 105),\n",
      "(304, '2023 Performance Review Cycle', 'Manage and execute the annual company-wide performance review cycle.', 'COMPLETED', '2023-07-01', '2023-08-31', 107),\n",
      "(305, 'Data Warehouse Migration', 'Migrate existing analytics data to a new cloud-based data warehouse solution.', 'ON_HOLD', '2023-09-01', '2024-01-15', 102);\n",
      "\n",
      "-- project_employees\n",
      "INSERT INTO project_employees (project_id, employee_id, role_on_project) VALUES\n",
      "(301, 104, 'Project Lead'), (301, 108, 'Lead Engineer'), (301, 109, 'Backend Engineer'), (301, 110, 'Lead Designer'),\n",
      "(302, 106, 'Product Lead'), (302, 108, 'AI/ML Engineer'), (302, 111, 'QA Lead'),\n",
      "(303, 105, 'Project Lead'), (303, 109, 'Mobile Engineer'), (303, 110, 'Mobile UX Designer'),\n",
      "(304, 107, 'HR Lead'), (304, 102, 'Executive Sponsor'), (304, 103, 'Executive Sponsor'),\n",
      "(301, 111, 'QA Engineer'), (302, 109, 'Backend Support');\n",
      "\n",
      "-- performance_reviews\n",
      "INSERT INTO performance_reviews (review_id, employee_id, reviewer_employee_id, review_period_start, review_period_end, overall_rating, summary_strengths, summary_areas_for_improvement) VALUES\n",
      "(401, 108, 104, '2023-01-01', '2023-06-30', 4.5, 'Henry consistently delivers high-quality code and is a go-to expert for complex backend issues. His work on the API refactor was exceptional.', 'Could be more proactive in sharing knowledge with junior team members and documenting complex systems.'),\n",
      "(402, 109, 105, '2023-01-01', '2023-06-30', 4.0, 'Isla has shown remarkable growth this period. She is a fast learner and has a great attitude. Her contributions to the Mobile App MVP have been significant.', 'Continue to build confidence in leading technical discussions and taking ownership of larger features.'),\n",
      "(403, 110, 103, '2023-01-01', '2023-06-30', 4.2, 'Jack''s design work is consistently excellent, intuitive, and user-centric. He collaborates effectively with both product and engineering.', 'Focus on developing data visualization skills to better present user research findings.');\n",
      "\n",
      "-- review_metrics\n",
      "INSERT INTO review_metrics (review_id, metric_id, rating, comments) VALUES\n",
      "(401, 201, 5, 'Top-tier technical skills in Python and system architecture.'),\n",
      "(401, 203, 4, 'Excellent collaborator within the core project team.'),\n",
      "(401, 204, 5, 'Highly effective at debugging and solving complex technical challenges.'),\n",
      "(402, 201, 4, 'Rapidly developing strong skills in React and mobile development.'),\n",
      "(402, 202, 3, 'Can be hesitant to speak up in larger meetings, but is very clear in 1-on-1s.'),\n",
      "(402, 203, 5, 'Always willing to help teammates and is a positive presence on the team.'),\n",
      "(403, 201, 5, 'Exceptional skill in UX/UI design principles and tools.'),\n",
      "(403, 202, 4, 'Clearly articulates design rationale and is receptive to feedback.');\n",
      "\n",
      "-- conversations\n",
      "INSERT INTO conversations (conversation_id, user_id, title) VALUES\n",
      "(501, 208, 'Career Path for Senior Engineer'),\n",
      "(502, 210, 'Project Brainstorming: Mobile App');\n",
      "\n",
      "-- conversation_messages\n",
      "INSERT INTO conversation_messages (conversation_id, sender_type, message_text) VALUES\n",
      "(501, 'USER', 'What are the typical career paths for a Senior Software Engineer at this company?'),\n",
      "(501, 'AI', 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'),\n",
      "(501, 'USER', 'Yes, tell me more about the skills for an Engineering Manager.'),\n",
      "(501, 'AI', 'To become an Engineering Manager, employees typically develop strong skills in Project Management, Performance Management, and Stakeholder Communication. Your manager, David Evans, is highly skilled in Project Management. You might consider asking him for mentorship opportunities.'),\n",
      "(502, 'USER', 'Help me brainstorm ideas for the new Mobile App MVP.'),\n",
      "(502, 'AI', 'Of course! The project goal is to create an MVP for iOS and Android. Based on similar successful projects, key features to consider are: 1. Employee Profile Viewing, 2. Skill Endorsements, 3. Project Directory Search, and 4. A simplified view of performance reviews. This aligns with the project description and leverages existing platform data.');\n",
      "\n",
      "-- project_comments\n",
      "INSERT INTO project_comments (comment_id, project_id, author_user_id, parent_comment_id, comment_text) VALUES\n",
      "(601, 301, 204, NULL, 'Team, let''s make sure we have the final architecture diagrams reviewed by EOD Friday. I''ve attached the latest version to the project docs.'),\n",
      "(602, 301, 208, 601, 'Sounds good, David. I''ve reviewed the diagrams and left a few comments regarding the database connection pooling strategy.'),\n",
      "(603, 301, 210, 601, 'From a design perspective, the new component library looks great. The handoff to engineering should be smooth.');\n",
      "\n",
      "COMMIT;\n"
     ]
    }
   ],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a data specialist. Based on the provided PRD and the exact SQL schema below, generate realistic SQL statements to seed the database for the onboarding tool.\n",
    "\n",
    "Requirements:\n",
    "- Inspect the provided SQL schema carefully (the `<schema>` block below and the file `artifacts/schema.sql`) and use the exact table and column names found there.\n",
    "- Produce a single SQL script that begins with `BEGIN;` and ends with `COMMIT;` to wrap all inserts in a transaction.\n",
    "- Ensure all `INSERT` statements respect column types, `NOT NULL` and `UNIQUE` constraints, and `FOREIGN KEY` relationships declared in the schema. If primary keys are `INTEGER PRIMARY KEY AUTOINCREMENT`, you may insert `NULL` for those columns and then reference the assigned values consistently for foreign keys, or insert explicit IDs — but relationships must be internally consistent.\n",
    "- Output only raw SQL (no markdown, no explanatory text).\n",
    "- Generate between 5 and 10 meaningful `INSERT` statements per major entity group (for example: users/project_managers/employees/applicants/onboarding_tasks) so the dataset is useful for development and testing.\n",
    "- Include at least 5 project managers and 3 employees, and a spread of onboarding tasks assigned to those users. Use realistic values for names, emails, dates (ISO 8601), and status fields consistent with the PRD.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "**SQL Schema:**\n",
    "<schema>\n",
    "{cleaned_schema}\n",
    "</schema>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    # Enhance the seed data prompt for better structure and fidelity\n",
    "    enhanced_seed_prompt = prompt_enhancer(seed_data_prompt)\n",
    "    print(\"Seed Data Enhanced prompt\\n\", enhanced_seed_prompt)\n",
    "\n",
    "    # Use the seed-data specific client\n",
    "    generated_seed_data = get_completion(enhanced_seed_prompt, seed_client, seed_model_name, seed_api_provider)\n",
    "\n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "\n",
    "    # Save the cleaned seed data to a file\n",
    "    save_artifact(cleaned_seed_data, \"artifacts/seed_data.sql\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Creating and Seeding a Live Database\n",
    "\n",
    "**Explanation:**\n",
    "This Python function demonstrates a crucial engineering task: turning text-based artifacts into a live system component. The `create_database` function uses Python's built-in `sqlite3` library.\n",
    "1.  It establishes a connection to a database file, which creates the file if it doesn't exist.\n",
    "2.  It reads the `schema.sql` artifact and executes it. It's important to use `cursor.executescript()` here. While `cursor.execute()` is designed for a single SQL statement, `executescript()` is necessary for running a string that contains multiple SQL statements, which is exactly what our `schema.sql` and `seed_data.sql` files contain.\n",
    "3.  It then reads and executes the `seed_data.sql` artifact to populate the newly created tables.\n",
    "4.  `conn.commit()` saves all the changes to the database file.\n",
    "5.  The `finally` block ensures that `conn.close()` is always called, which is a critical best practice to prevent resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to database at c:\\Users\\labadmin\\Documents\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\artifacts\\main_database.db\n",
      "Tables created successfully.\n",
      "Seed data inserted successfully.\n",
      "Database changes committed.\n",
      "Tables created successfully.\n",
      "Seed data inserted successfully.\n",
      "Database changes committed.\n"
     ]
    }
   ],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "\n",
    "    # Delete the old database file if it exists to start fresh\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "        print(f\"Removed existing database file at {db_path}\")\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        # Enable foreign key enforcement for this connection\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read and execute the schema file\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if schema_sql:\n",
    "            cursor.executescript(schema_sql)\n",
    "            print(\"Tables created successfully.\")\n",
    "\n",
    "        # Read and execute the seed data file if it exists\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted successfully.\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(os.getcwd(), \"artifacts\", \"main_database.db\")\n",
    "schema_file = os.path.join(os.getcwd(), \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(os.getcwd(), \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function to create and seed the database\n",
    "create_database(db_file, schema_file, seed_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Verify the database was created successfully by querying the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database at c:\\Users\\labadmin\\Documents\\220372-AG-AISOFTDEV-Team-2-CodeVoyagers\\artifacts\\main_database.db\n",
      "Table 'departments' contains 5 records\n",
      "--- Sample rows from departments ---\n",
      "{'department_id': 1, 'name': 'Engineering', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'department_id': 2, 'name': 'Product Management', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'department_id': 3, 'name': 'Human Resources', 'created_at': '2025-11-06 14:52:54'}\n",
      "Table 'employees' contains 11 records\n",
      "--- Sample rows from employees ---\n",
      "{'employee_id': 101, 'first_name': 'Aria', 'last_name': 'Chen', 'email': 'aria.chen@talentsphere.ai'}\n",
      "{'employee_id': 102, 'first_name': 'Ben', 'last_name': 'Carter', 'email': 'ben.carter@talentsphere.ai'}\n",
      "{'employee_id': 103, 'first_name': 'Chloe', 'last_name': 'Davis', 'email': 'chloe.davis@talentsphere.ai'}\n",
      "Table 'users' contains 11 records\n",
      "--- Sample rows from users ---\n",
      "{'user_id': 201, 'employee_id': 101, 'sso_subject_id': 'auth0|64f8a9b1c2d3e4f5a6b7c8d9', 'is_active': 1}\n",
      "{'user_id': 202, 'employee_id': 102, 'sso_subject_id': 'auth0|64f8a9b2c3d4e5f6a7b8c9d0', 'is_active': 1}\n",
      "{'user_id': 203, 'employee_id': 103, 'sso_subject_id': 'auth0|64f8a9b3c4d5e6f7a8b9cad1', 'is_active': 1}\n",
      "Table 'roles' contains 4 records\n",
      "--- Sample rows from roles ---\n",
      "{'role_id': 1, 'role_name': 'PROJECT_MANAGER'}\n",
      "{'role_id': 2, 'role_name': 'HR_PARTNER'}\n",
      "{'role_id': 3, 'role_name': 'TEAM_LEAD'}\n",
      "Table 'user_roles' contains 19 records\n",
      "--- Sample rows from user_roles ---\n",
      "{'user_id': 202, 'role_id': 1}\n",
      "{'user_id': 203, 'role_id': 1}\n",
      "{'user_id': 204, 'role_id': 1}\n",
      "Table 'skills' contains 10 records\n",
      "--- Sample rows from skills ---\n",
      "{'skill_id': 101, 'name': 'Python', 'category': 'Technical', 'description': 'Proficiency in Python programming language for backend development and data analysis.'}\n",
      "{'skill_id': 102, 'name': 'SQL', 'category': 'Technical', 'description': 'Advanced knowledge of SQL for database management and querying.'}\n",
      "{'skill_id': 103, 'name': 'Project Management', 'category': 'Management', 'description': 'Skills in planning, executing, and closing projects.'}\n",
      "Table 'employee_skills' contains 25 records\n",
      "--- Sample rows from employee_skills ---\n",
      "{'employee_skill_id': 1, 'employee_id': 102, 'skill_id': 103, 'proficiency_level': 5}\n",
      "{'employee_skill_id': 2, 'employee_id': 102, 'skill_id': 104, 'proficiency_level': 5}\n",
      "{'employee_skill_id': 3, 'employee_id': 102, 'skill_id': 107, 'proficiency_level': 4}\n",
      "Table 'projects' contains 5 records\n",
      "--- Sample rows from projects ---\n",
      "{'project_id': 301, 'name': 'Q4 Platform Overhaul', 'description': 'A complete redesign and re-architecture of the main TalentSphere platform.', 'status': 'ACTIVE'}\n",
      "{'project_id': 302, 'name': 'AI Co-pilot Integration', 'description': 'Integrate a new generative AI assistant into the performance review module.', 'status': 'ACTIVE'}\n",
      "{'project_id': 303, 'name': 'Mobile App MVP', 'description': 'Develop the minimum viable product for the TalentSphere iOS and Android applications.', 'status': 'PLANNED'}\n",
      "Table 'project_employees' contains 15 records\n",
      "--- Sample rows from project_employees ---\n",
      "{'project_employee_id': 1, 'project_id': 301, 'employee_id': 104, 'role_on_project': 'Project Lead'}\n",
      "{'project_employee_id': 2, 'project_id': 301, 'employee_id': 108, 'role_on_project': 'Lead Engineer'}\n",
      "{'project_employee_id': 3, 'project_id': 301, 'employee_id': 109, 'role_on_project': 'Backend Engineer'}\n",
      "Table 'metrics' contains 5 records\n",
      "--- Sample rows from metrics ---\n",
      "{'metric_id': 201, 'name': 'Technical Proficiency', 'description': 'Demonstrates mastery of technical skills required for the role.'}\n",
      "{'metric_id': 202, 'name': 'Communication', 'description': 'Effectively conveys information and ideas to others.'}\n",
      "{'metric_id': 203, 'name': 'Teamwork & Collaboration', 'description': 'Works effectively with team members to achieve common goals.'}\n",
      "Table 'performance_reviews' contains 3 records\n",
      "--- Sample rows from performance_reviews ---\n",
      "{'review_id': 401, 'employee_id': 108, 'reviewer_employee_id': 104, 'review_period_start': '2023-01-01'}\n",
      "{'review_id': 402, 'employee_id': 109, 'reviewer_employee_id': 105, 'review_period_start': '2023-01-01'}\n",
      "{'review_id': 403, 'employee_id': 110, 'reviewer_employee_id': 103, 'review_period_start': '2023-01-01'}\n",
      "Table 'review_metrics' contains 8 records\n",
      "--- Sample rows from review_metrics ---\n",
      "{'review_metric_id': 1, 'review_id': 401, 'metric_id': 201, 'rating': 5}\n",
      "{'review_metric_id': 2, 'review_id': 401, 'metric_id': 203, 'rating': 4}\n",
      "{'review_metric_id': 3, 'review_id': 401, 'metric_id': 204, 'rating': 5}\n",
      "Table 'conversations' contains 2 records\n",
      "--- Sample rows from conversations ---\n",
      "{'conversation_id': 501, 'user_id': 208, 'title': 'Career Path for Senior Engineer', 'created_at': '2025-11-06 14:52:54'}\n",
      "{'conversation_id': 502, 'user_id': 210, 'title': 'Project Brainstorming: Mobile App', 'created_at': '2025-11-06 14:52:54'}\n",
      "Table 'conversation_messages' contains 6 records\n",
      "--- Sample rows from conversation_messages ---\n",
      "{'message_id': 1, 'conversation_id': 501, 'sender_type': 'USER', 'message_text': 'What are the typical career paths for a Senior Software Engineer at this company?'}\n",
      "{'message_id': 2, 'conversation_id': 501, 'sender_type': 'AI', 'message_text': 'Based on our data, Senior Software Engineers often progress to roles like Staff Engineer, Engineering Manager, or Solutions Architect. Key skills for these paths include system design, project leadership, and mentorship. Would you like to explore the skills required for the Engineering Manager path?'}\n",
      "{'message_id': 3, 'conversation_id': 501, 'sender_type': 'USER', 'message_text': 'Yes, tell me more about the skills for an Engineering Manager.'}\n",
      "Table 'project_comments' contains 3 records\n",
      "--- Sample rows from project_comments ---\n",
      "{'comment_id': 601, 'project_id': 301, 'author_user_id': 204, 'parent_comment_id': None}\n",
      "{'comment_id': 602, 'project_id': 301, 'author_user_id': 208, 'parent_comment_id': 601}\n",
      "{'comment_id': 603, 'project_id': 301, 'author_user_id': 210, 'parent_comment_id': 601}\n"
     ]
    }
   ],
   "source": [
    "# Verify the database was created successfully by querying the data\n",
    "def verify_database(db_path, schema_path=None):\n",
    "    \"\"\"Verify the database contains the expected data based on the generated schema.\"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Database file not found at {db_path}\")\n",
    "        return\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        # Ensure foreign keys are enforced for verification queries\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON\")\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Connected to database at {db_path}\")\n",
    "\n",
    "        # Determine expected tables from the provided schema if available\n",
    "        schema_sql = \"\"\n",
    "        if schema_path and os.path.exists(schema_path):\n",
    "            schema_sql = load_artifact(schema_path) or \"\"\n",
    "        elif 'cleaned_schema' in globals() and cleaned_schema:\n",
    "            schema_sql = cleaned_schema\n",
    "\n",
    "        table_names = []\n",
    "        if schema_sql:\n",
    "            import re\n",
    "            # Extract table names from CREATE TABLE statements\n",
    "            matches = re.findall(r'CREATE\\s+TABLE\\s+(?:IF\\s+NOT\\s+EXISTS\\s+)?[\"`]?(\\w+)[\"`]?', schema_sql, flags=re.IGNORECASE)\n",
    "            table_names = list(dict.fromkeys(matches))  # preserve order, remove duplicates\n",
    "\n",
    "        # Fallback to common expected tables if schema parsing found nothing\n",
    "        if not table_names:\n",
    "            table_names = ['users', 'applicants', 'onboarding_tasks']\n",
    "\n",
    "        # Query each table for counts and a small sample of rows\n",
    "        for t in table_names:\n",
    "            try:\n",
    "                cursor.execute(f\"SELECT COUNT(*) FROM {t}\")\n",
    "                count = cursor.fetchone()[0]\n",
    "                print(f\"Table '{t}' contains {count} records\")\n",
    "\n",
    "                # Get column names to present a representative sample row as a dict\n",
    "                cursor.execute(f\"PRAGMA table_info({t})\")\n",
    "                cols = [r[1] for r in cursor.fetchall()]\n",
    "                if cols:\n",
    "                    sel_cols = cols[:4]  # limit number of displayed columns\n",
    "                    cursor.execute(f\"SELECT {', '.join(sel_cols)} FROM {t} LIMIT 3\")\n",
    "                    rows = cursor.fetchall()\n",
    "                    if rows:\n",
    "                        print(f\"--- Sample rows from {t} ---\")\n",
    "                        for row in rows:\n",
    "                            # Align values with column names for readability\n",
    "                            sample = dict(zip(sel_cols, row))\n",
    "                            print(sample)\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Could not query table {t}: {e}\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Verify the database using the generated schema when available\n",
    "verify_database(db_file, schema_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
