{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Explanation:**\n",
    "We load the `day1_prd.md` artifact from Day 1. This document is the single source of truth for our project's requirements and provides the essential context for the LLM to generate a relevant and accurate database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output, recommended_models_table, prompt_enhancer\n",
    "\n",
    "# Initialize separate LLM clients for different artifacts to use the latest models from different providers.\n",
    "# - Schema generation uses a strong instruction-following model\n",
    "# - Seed data generation uses a model tuned for data generation\n",
    "schema_client, schema_model_name, schema_api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "seed_client, seed_model_name, seed_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the PRD\n",
    "prd_content = load_artifact(\"artifacts/adr_001_database_choice.md\")\n",
    "if not prd_content:\n",
    "    print(\"Warning: Could not load prd_content = artifacts/adr_001_database_choice.md. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 - Generating the SQL Schema\n",
    "\n",
    "**Explanation:**\n",
    "This prompt instructs the LLM to act as a Database Administrator (DBA). By providing the full PRD as context, we enable the LLM to understand the entities and relationships required by the application. The prompt specifically asks for `CREATE TABLE` statements, guiding the LLM to produce a ready-to-use SQL script. We then clean up the response to remove markdown fences and save the pure SQL code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_prompt = f\"\"\"\n",
    "You are a Database Administrator. Based on the provided PRD, generate SQL `CREATE TABLE` statements to define the database schema for an onboarding tool.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "Ensure the schema includes:\n",
    "1. A `users` table with fields for `id`, `name`, `email`, and `role`.\n",
    "2. An `onboarding_tasks` table with fields for `id`, `title`, `description`, `assigned_to` (foreign key to `users`), and `status`.\n",
    "3. An `applicants` table that matches the fields used by index.html. This table should include:\n",
    "    - `id` (primary key, integer, autoincrement)\n",
    "    - `name` (text)\n",
    "    - `title` (text)\n",
    "    - `experience_years` (integer)\n",
    "    - `education` (text)\n",
    "    - `location` (text)\n",
    "    - `skills` (text) -- store as a comma-separated list or JSON text\n",
    "    - `summary` (text)\n",
    "\n",
    "Make sure to include proper data types, primary keys, foreign keys, and sensible constraints (e.g., unique on emails where appropriate, not null where required). If any relationships are needed between `applicants` and other tables, include them and document via comments in the SQL.\n",
    "\n",
    "Output only the raw SQL code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "     # Enhance the raw schema prompt using the project's prompt enhancer\n",
    "     enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "     print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "\n",
    "     # Send the enhanced prompt to the schema-specific LLM client\n",
    "     generated_schema = get_completion(enhanced_schema_prompt, schema_client, schema_model_name, schema_api_provider)\n",
    "\n",
    "     # Clean up the generated schema\n",
    "     cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "     print(cleaned_schema)\n",
    "\n",
    "     # Save the cleaned schema to a file\n",
    "     save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "else:\n",
    "     print(\"Skipping schema generation because PRD is missing.\")\n",
    "     cleaned_schema = \"\"\n",
    "\n",
    "print(\"--- Generating SQL Schema ---\")\n",
    "if prd_content:\n",
    "    # Enhance the raw schema prompt using the project's prompt enhancer\n",
    "    enhanced_schema_prompt = prompt_enhancer(schema_prompt)\n",
    "    print(\"Schema Enhanced prompt\\n\", enhanced_schema_prompt)\n",
    "\n",
    "    # Send the enhanced prompt to the schema-specific LLM client\n",
    "    generated_schema = get_completion(enhanced_schema_prompt, schema_client, schema_model_name, schema_api_provider)\n",
    "\n",
    "    # Clean up the generated schema\n",
    "    cleaned_schema = clean_llm_output(generated_schema, language='sql')\n",
    "    print(cleaned_schema)\n",
    "\n",
    "    # Save the cleaned schema to a file\n",
    "    save_artifact(cleaned_schema, \"artifacts/schema.sql\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping schema generation because PRD is missing.\")\n",
    "    cleaned_schema = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Generating Realistic Seed Data\n",
    "\n",
    "**Explanation:**\n",
    "An empty database isn't very useful for development. This prompt asks the LLM to generate realistic seed data. By providing both the PRD (for thematic context) and the SQL schema (for structural correctness), we guide the LLM to create `INSERT` statements that are both thematically appropriate (e.g., onboarding-related task titles) and syntactically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_data_prompt = f\"\"\"\n",
    "You are a data specialist. Based on the provided PRD and SQL schema, generate 5-10 realistic SQL `INSERT` statements to populate the tables with sample data for an onboarding tool.\n",
    "\n",
    "**PRD Context:**\n",
    "<prd>\n",
    "{prd_content}\n",
    "</prd>\n",
    "\n",
    "**SQL Schema:**\n",
    "<schema>\n",
    "{cleaned_schema}\n",
    "</schema>\n",
    "\n",
    "Generate at least 5 project managers and 3 employees.\n",
    "Output only the raw SQL `INSERT` statements.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Seed Data ---\")\n",
    "if prd_content and cleaned_schema:\n",
    "    # Enhance the seed data prompt for better structure and fidelity\n",
    "    enhanced_seed_prompt = prompt_enhancer(seed_data_prompt)\n",
    "    print(\"Seed Data Enhanced prompt\\n\", enhanced_seed_prompt)\n",
    "\n",
    "    # Use the seed-data specific client\n",
    "    generated_seed_data = get_completion(enhanced_seed_prompt, seed_client, seed_model_name, seed_api_provider)\n",
    "\n",
    "    # Clean up the generated seed data\n",
    "    cleaned_seed_data = clean_llm_output(generated_seed_data, language='sql')\n",
    "    print(cleaned_seed_data)\n",
    "\n",
    "    # Save the cleaned seed data to a file\n",
    "    save_artifact(cleaned_seed_data, \"artifacts/seed_data.sql\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping seed data generation because PRD or schema is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Creating and Seeding a Live Database\n",
    "\n",
    "**Explanation:**\n",
    "This Python function demonstrates a crucial engineering task: turning text-based artifacts into a live system component. The `create_database` function uses Python's built-in `sqlite3` library.\n",
    "1.  It establishes a connection to a database file, which creates the file if it doesn't exist.\n",
    "2.  It reads the `schema.sql` artifact and executes it. It's important to use `cursor.executescript()` here. While `cursor.execute()` is designed for a single SQL statement, `executescript()` is necessary for running a string that contains multiple SQL statements, which is exactly what our `schema.sql` and `seed_data.sql` files contain.\n",
    "3.  It then reads and executes the `seed_data.sql` artifact to populate the newly created tables.\n",
    "4.  `conn.commit()` saves all the changes to the database file.\n",
    "5.  The `finally` block ensures that `conn.close()` is always called, which is a critical best practice to prevent resource leaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(db_path, schema_path, seed_path):\n",
    "    \"\"\"Creates and seeds a SQLite database from SQL files.\"\"\"\n",
    "    if not os.path.exists(schema_path):\n",
    "        print(f\"Error: Schema file not found at {schema_path}\")\n",
    "        return\n",
    "\n",
    "    # Delete the old database file if it exists to start fresh\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "        print(f\"Removed existing database file at {db_path}\")\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        print(f\"Successfully connected to database at {db_path}\")\n",
    "\n",
    "        # Read and execute the schema file\n",
    "        schema_sql = load_artifact(schema_path)\n",
    "        if schema_sql:\n",
    "            cursor.executescript(schema_sql)\n",
    "            print(\"Tables created successfully.\")\n",
    "\n",
    "        # Read and execute the seed data file if it exists\n",
    "        if os.path.exists(seed_path):\n",
    "            seed_sql = load_artifact(seed_path)\n",
    "            if seed_sql:\n",
    "                cursor.executescript(seed_sql)\n",
    "                print(\"Seed data inserted successfully.\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Database changes committed.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            print(\"Database connection closed.\")\n",
    "\n",
    "# Define file paths\n",
    "db_file = os.path.join(os.getcwd(), \"artifacts\", \"main_database.db\")\n",
    "schema_file = os.path.join(os.getcwd(), \"artifacts\", \"schema.sql\")\n",
    "seed_file = os.path.join(os.getcwd(), \"artifacts\", \"seed_data.sql\")\n",
    "\n",
    "# Execute the function\n",
    "create_database(db_file, schema_file, seed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Verify the database was created successfully by querying the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the database was created successfully by querying the data\n",
    "def verify_database(db_path):\n",
    "    \"\"\"Verify the database contains the expected data\"\"\"\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"Database file not found at {db_path}\")\n",
    "        return\n",
    "    \n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Check users table\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM users\")\n",
    "        user_count = cursor.fetchone()[0]\n",
    "        print(f\"Users table contains {user_count} records\")\n",
    "        \n",
    "        # Check applicants table\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM applicants\")\n",
    "        applicant_count = cursor.fetchone()[0]\n",
    "        print(f\"Applicants table contains {applicant_count} records\")\n",
    "        \n",
    "        # Check onboarding_tasks table\n",
    "        cursor.execute(\"SELECT COUNT(*) FROM onboarding_tasks\")\n",
    "        task_count = cursor.fetchone()[0]\n",
    "        print(f\"Onboarding_tasks table contains {task_count} records\")\n",
    "        \n",
    "        # Show sample data\n",
    "        print(\"\\n--- Sample Users ---\")\n",
    "        cursor.execute(\"SELECT id, name, email, role FROM users LIMIT 3\")\n",
    "        for row in cursor.fetchall():\n",
    "            print(f\"ID: {row[0]}, Name: {row[1]}, Email: {row[2]}, Role: {row[3]}\")\n",
    "            \n",
    "        print(\"\\n--- Sample Applicants ---\")\n",
    "        cursor.execute(\"SELECT id, name, title, experience_years FROM applicants LIMIT 3\")\n",
    "        for row in cursor.fetchall():\n",
    "            print(f\"ID: {row[0]}, Name: {row[1]}, Title: {row[2]}, Experience: {row[3]} years\")\n",
    "            \n",
    "        print(\"\\n--- Sample Tasks ---\")\n",
    "        cursor.execute(\"SELECT id, title, status, assigned_to FROM onboarding_tasks LIMIT 3\")\n",
    "        for row in cursor.fetchall():\n",
    "            print(f\"ID: {row[0]}, Title: {row[1]}, Status: {row[2]}, Assigned to: {row[3]}\")\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "# Verify the database\n",
    "verify_database(db_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
