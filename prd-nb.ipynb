{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca2131f9",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "**PRD Development**\n",
    "\n",
    "Generate recruiters and stories..\n",
    "generate PRD from user stories?\n",
    "Who does the recruiters need to hire? Are they looking for ____?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4619ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "# Load the artifact from Lab 1\n",
    "user_stories_data = load_artifact(\"day1_user_stories.json\")\n",
    "if not user_stories_data:\n",
    "    user_stories_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc02b842",
   "metadata": {},
   "source": [
    "**Problem Statement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb2bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"Assess applicants for recruitment towards specific jobs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a string variable named 'features_prompt'.\n",
    "# This prompt should ask the LLM to brainstorm features based on the problem_statement.\n",
    "features_prompt = \"\"\" REPLACE \"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# TODO: Create a string variable named 'personas_prompt'.\n",
    "# This prompt should ask the LLM to identify three user personas based on the problem_statement.\n",
    "personas_prompt = \"\"\" REPLACE\"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a53abd",
   "metadata": {},
   "source": [
    "**User Stories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d250c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a detailed prompt string named 'json_user_stories_prompt'.\n",
    "# CREATE BOTH RECRUITERS/HR AND APPLICANTS USER STORIES?\n",
    "json_user_stories_prompt = f\"\"\" REPLACE \"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Let's try to parse the JSON to see if the LLM followed instructions\n",
    "try:\n",
    "    # The LLM might wrap the JSON in markdown fences (```json ... ```).\n",
    "    # We'll clean that up before parsing.\n",
    "    if '```' in json_output_str:\n",
    "        json_output_str = json_output_str.split('```')[1].lstrip('json').strip()\n",
    "    \n",
    "    user_stories_json = json.loads(json_output_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    \n",
    "    if user_stories_json:\n",
    "        print(\"\\n--- Sample User Story ---\")\n",
    "        print(json.dumps(user_stories_json[0], indent=2))\n",
    "    else:\n",
    "        print(\"JSON array is empty.\")\n",
    "\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4444e",
   "metadata": {},
   "source": [
    "**Validate Stories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67985b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # TODO: Implement the validation logic inside this function.\n",
    "    # 1. Loop through each story in the 'stories_data' list.\n",
    "    # 2. For each story, check if it contains all the 'required_keys'.\n",
    "    # 3. Also check if the 'acceptance_criteria' list is not empty.\n",
    "    # 4. If a story is invalid, print an error message and set 'all_stories_valid' to False.\n",
    "    #    (You can use 'continue' to skip to the next story).\n",
    "\n",
    "    # Your validation code here\n",
    "    for i, story in enumerate(stories_data, 1):\n",
    "        # Check if story is a dictionary\n",
    "        if not isinstance(story, dict):\n",
    "            print(f\"Error: Story {i} is not a dictionary.\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "            \n",
    "        # Check if all required keys are present\n",
    "        missing_keys = [key for key in required_keys if key not in story]\n",
    "        if missing_keys:\n",
    "            print(f\"Error: Story {i} is missing required keys: {missing_keys}\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "            \n",
    "        # Check if acceptance_criteria is not empty\n",
    "        acceptance_criteria = story.get('acceptance_criteria')\n",
    "        if not acceptance_criteria or (isinstance(acceptance_criteria, list) and len(acceptance_criteria) == 0):\n",
    "            print(f\"Error: Story {i} has empty acceptance_criteria.\")\n",
    "            all_stories_valid = False\n",
    "            continue\n",
    "            \n",
    "        print(f\"Story {i}: Valid\")\n",
    "\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # TODO: Call the save_artifact function from utils.py to save the data.\n",
    "        # Remember to convert the Python list back to a JSON string using json.dumps().\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        print(f\"User stories saved to {artifact_path}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation on the JSON data from the previous step\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e090c7",
   "metadata": {},
   "source": [
    "**Generate PRD**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e94f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a simple PRD.\n",
    "simple_prd_prompt = f\"\"\" REPLACE\"\"\"\n",
    "\n",
    "print(\"--- Generating Simple PRD ---\")\n",
    "if user_stories_data:\n",
    "    simple_prd_output = get_completion(simple_prd_prompt, client, model_name, api_provider)\n",
    "    print(simple_prd_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories are missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3648e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PRD template directly using the project root path\n",
    "template_path = os.path.join(project_root, \"templates\", \"prd_template.md\")\n",
    "try:\n",
    "    with open(template_path, 'r', encoding='utf-8') as f:\n",
    "        prd_template_content = f.read()\n",
    "    print(f\"Successfully loaded template from: {template_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Template file not found at: {template_path}\")\n",
    "    prd_template_content = \"\"\n",
    "except Exception as e:\n",
    "    print(f\"Error loading template: {e}\")\n",
    "    prd_template_content = \"\"\n",
    "\n",
    "# TODO: Write a prompt to populate the PRD template.\n",
    "template_prd_prompt = f\"\"\" REPLACE \"\"\"\n",
    "\n",
    "print(\"--- Generating PRD from Template ---\")\n",
    "if user_stories_data and prd_template_content:\n",
    "    prd_from_template_output = get_completion(template_prd_prompt, client, model_name, api_provider)\n",
    "    print(prd_from_template_output)\n",
    "else:\n",
    "    print(\"Skipping PRD generation because user stories or template are missing.\")\n",
    "    prd_from_template_output = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a Pydantic model for the PRD.\n",
    "# Tip: Be specific. Tell the LLM to create a class named 'ProductRequirementsDocument' and to use appropriate types from Python's 'typing' library.\n",
    "pydantic_model_prompt = f\"\"\" REPLACE\"\"\"\n",
    "\n",
    "print(\"--- Generating Pydantic Model for PRD ---\")\n",
    "if prd_template_content:\n",
    "    pydantic_model_code = get_completion(pydantic_model_prompt, client, model_name, api_provider)\n",
    "    \n",
    "    # Clean up the code if it's wrapped in markdown fences\n",
    "    if '```' in pydantic_model_code:\n",
    "        pydantic_model_code = pydantic_model_code.split('```')[1].lstrip('python').strip()\n",
    "    \n",
    "    print(\"\\n--- Generated Pydantic Model ---\")\n",
    "    print(pydantic_model_code)\n",
    "\n",
    "    # Save the generated Pydantic model code to a file.\n",
    "    model_path = \"app/validation_models/prd_model.py\"\n",
    "    save_artifact(pydantic_model_code, model_path)\n",
    "else:\n",
    "    print(\"Skipping Pydantic model generation because template is missing.\")\n",
    "\n",
    "# Finally, save the completed PRD from the intermediate challenge\n",
    "if prd_from_template_output:\n",
    "    save_artifact(prd_from_template_output, \"day1_prd.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848b926",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "**Generate design and architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bb6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to generate a markdown ADR template.\n",
    "adr_template_prompt = \"\"\"REPLACE \"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "# Save the artifact (overwrite if it already exists to avoid ArtifactError)\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a prompt to research database options.\n",
    "db_research_prompt = \"\"\"\n",
    "REPLACE\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f038dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "adr_template = load_artifact(\"artifacts/adr_template.md\")\n",
    "\n",
    "# TODO: Write a prompt to synthesize the final ADR.\n",
    "today = date.today().isoformat()\n",
    "\n",
    "synthesis_prompt = f\"\"\"REPLACE\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\", overwrite=True)\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
